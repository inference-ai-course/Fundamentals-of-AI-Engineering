# Level 3 Capstone：企业级私有化模型解决方案（全链路闭环）

## 项目目标

从数据到上线，完成“**数据清洗 -> 微调 -> 评测 -> 量化 -> 高并发部署**”的闭环交付，并用证据回答：

*   **效果是否提升？提升在哪里？代价是什么？**
*   **性能是否达标？瓶颈在哪里？成本如何控制？**
*   **风险与限制是什么？如何监控与降级？**

## 建议选题

选择一个可收集到足够指令数据的垂直任务（例）：

*   企业客服问答（FAQ/工单总结/标准回复）
*   领域写作与审校（合同条款审阅、合规改写、报告生成）
*   结构化信息抽取（票据/条款/表格转结构化）

## 必选范围（Must Have）

### 1）数据链路

*   数据收集与清洗策略说明
*   数据版本化（至少做到“能说清楚这次训练用了哪份数据”）
*   数据审计报告（长度、重复、异常、敏感）

### 2）微调链路

*   训练配置可复现
*   至少一次 LoRA/QLoRA 微调
*   失败复盘（至少 1 次失败实验）

### 3）评测链路

*   基准集（小而有效）
*   对比：base vs tuned（必要时再加 tuned-v2）
*   输出：指标 + 失败样例 + 结论（提升/不提升的原因）

### 4）量化与回归

*   至少一次量化实验
*   质量回归评测（证明量化没有不可接受的退化）

### 5）部署与压测

*   推理服务化（HTTP 接口）
*   最小可观测：健康检查 + 日志 + 基本指标
*   压测报告：吞吐、延迟分布（p95/p99）、并发上限与瓶颈分析

## 交付物（Deliverables）

*   一条可复现流水线：数据版本化 -> 训练 -> 评测 -> 导出 -> 部署（脚本/Makefile/CI 均可）
*   一份“效果证据包”：
    *   基线 vs 微调 vs（可选）迭代版 的对比
    *   失败样例分析（至少 20 条）
    *   偏差与风险说明（例如过拟合、幻觉、敏感内容）
*   一份“性能与成本报告”：
    *   吞吐/延迟/资源占用/并发策略与上限
    *   优化动作与收益（至少 1 项具体优化）
*   一份“Meta Learning 证据包”：
    *   Issue Dossier（复杂问题排障档案）
    *   源码阅读记录或 Paper-to-Code 复现记录（二选一，或都做）

## 验收标准（Acceptance）

*   **评测可复现**：同一版本代码与数据，结果波动在可解释范围
*   **效果有证据**：明确说明在哪类样例上变好/变坏以及原因
*   **部署可用**：具备健康检查、基本监控指标、错误处理与降级策略
*   **性能有证据**：提供压测复现步骤与 p95/p99 数据

## 评分维度（Rubric，建议）

*   全链路完整度与可复现性：30%
*   效果证据与评测质量：30%
*   性能、稳定性与成本意识：25%
*   Meta Learning 证据（源码/论文/排障）：15%

## 加分项（Stretch Goals）

*   在线 A/B 或回放评测（Replay Evaluation）
*   风险治理：红队测试、敏感内容过滤与审计
*   自动化迭代：失败样例回收 -> 生成新数据 -> 再训练/再评测
*   多模型路由：按成本/延迟/质量动态选择模型
