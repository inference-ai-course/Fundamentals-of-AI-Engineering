{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 — Part 04: Testing strategy (pytest vs smoke tests)\n",
    "\n",
    "**Estimated time:** 45–75 minutes\n",
    "\n",
    "## What success looks like (end of Part 04)\n",
    "\n",
    "- You can name at least 3 checks (happy path, edge case, failure case).\n",
    "- Your checks verify artifacts/JSON validity rather than exact LLM text.\n",
    "- You can run a minimal smoke test that creates expected files under `output/`.\n",
    "\n",
    "### Checkpoint\n",
    "\n",
    "After running this notebook, you should be able to:\n",
    "\n",
    "- point to one “happy path” check\n",
    "- point to one “expected failure” check\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Distinguish unit tests from smoke tests\n",
    "- Write a minimal test plan (happy, edge, failure cases)\n",
    "- Check artifacts and JSON validity instead of exact text\n",
    "- Choose pytest or a smoke-test script for Level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45828ae1",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Tests are executable checks that protect you from regressions.\n",
    "\n",
    "---\n",
    "\n",
    "## Underlying theory: tests reduce uncertainty when you change things\n",
    "\n",
    "Every change introduces risk. Tests keep the system stable while you iterate.\n",
    "\n",
    "Two common layers:\n",
    "\n",
    "- **unit tests**: small, fast checks (parsing, validation, file handling)\n",
    "- **smoke tests**: end-to-end checks (pipeline runs and produces artifacts)\n",
    "\n",
    "For LLM projects, you often cannot assert exact text outputs. Instead assert:\n",
    "\n",
    "- output is valid JSON\n",
    "- required keys exist\n",
    "- file artifacts are created\n",
    "- failures are handled gracefully\n",
    "\n",
    "For Level 1 you can choose:\n",
    "\n",
    "- `pytest` unit tests (preferred)\n",
    "- or a `smoke_test.py` + manual checklist (acceptable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2681e2da",
   "metadata": {},
   "source": [
    "## Minimal test plan (3+ cases)\n",
    "\n",
    "You should have at least:\n",
    "\n",
    "- **happy path**: normal input works\n",
    "- **edge case**: missing values or tiny CSV\n",
    "- **failure case**: missing file / invalid schema\n",
    "\n",
    "Practical tip: smoke tests can be “one command” checks that run in CI later. The key is making them deterministic enough to be repeatable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d051e96",
   "metadata": {},
   "source": [
    "import json\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def require_file(path: str) -> Path:\n",
    "    p = Path(path).expanduser()\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(\"Input file not found: %s\" % p)\n",
    "    if p.stat().st_size == 0:\n",
    "        raise ValueError(\"Input file is empty: %s\" % p)\n",
    "    return p\n",
    "\n",
    "\n",
    "def test_require_file_missing(tmp_path):\n",
    "    # TODO: implement pytest unit test for missing file.\n",
    "    # Example: call require_file() and assert FileNotFoundError.\n",
    "    missing = Path(tmp_path) / \"missing.csv\"\n",
    "    try:\n",
    "        _ = require_file(str(missing))\n",
    "    except FileNotFoundError:\n",
    "        return\n",
    "    raise AssertionError(\"expected FileNotFoundError\")\n",
    "\n",
    "\n",
    "def test_require_file_empty(tmp_path):\n",
    "    # TODO: implement pytest unit test for empty file.\n",
    "    p = Path(tmp_path) / \"empty.csv\"\n",
    "    p.write_text(\"\", encoding=\"utf-8\")\n",
    "    try:\n",
    "        _ = require_file(str(p))\n",
    "    except ValueError:\n",
    "        return\n",
    "    raise AssertionError(\"expected ValueError\")\n",
    "\n",
    "\n",
    "def smoke_test_pipeline() -> None:\n",
    "    # TODO: run an end-to-end pipeline with a tiny input.\n",
    "    # Verify artifacts exist: output/report.json, output/report.md\n",
    "    out_dir = Path(\"output\")\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "    (out_dir / \"report.json\").write_text(json.dumps({\"ok\": True}, indent=2), encoding=\"utf-8\")\n",
    "    (out_dir / \"report.md\").write_text(\"# Report\\n\\nOK\", encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "with tempfile.TemporaryDirectory() as d:\n",
    "    test_require_file_missing(d)\n",
    "    test_require_file_empty(d)\n",
    "\n",
    "smoke_test_pipeline()\n",
    "print(\"wrote:\", Path(\"output\") / \"report.json\")\n",
    "print(\"Implement pytest tests + smoke_test_pipeline().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efff011",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- pytest docs: https://docs.pytest.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef28ef",
   "metadata": {},
   "source": [
    "## Appendix: Solutions (peek only after trying)\n",
    "\n",
    "Reference implementations for pytest-style tests and a smoke test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8081815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_require_file_missing(tmp_path):\n",
    "    import pytest\n",
    "\n",
    "    missing = Path(tmp_path) / \"missing.csv\"\n",
    "    with pytest.raises(FileNotFoundError):\n",
    "        _ = require_file(str(missing))\n",
    "\n",
    "\n",
    "def test_require_file_empty(tmp_path):\n",
    "    import pytest\n",
    "\n",
    "    p = Path(tmp_path) / \"empty.csv\"\n",
    "    p.write_text(\"\", encoding=\"utf-8\")\n",
    "    with pytest.raises(ValueError):\n",
    "        _ = require_file(str(p))\n",
    "\n",
    "\n",
    "def smoke_test_pipeline() -> None:\n",
    "    out_dir = Path(\"output\")\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "    (out_dir / \"report.json\").write_text(json.dumps({\"ok\": True}, indent=2), encoding=\"utf-8\")\n",
    "    (out_dir / \"report.md\").write_text(\"# Report\\n\\nOK\", encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "print(\"solution smoke wrote:\", Path(\"output\") / \"report.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
