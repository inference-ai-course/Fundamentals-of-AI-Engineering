{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Level 1 — Week 7 Practice (Starter Notebook)\n",
        "\n",
        "This notebook provides starter scaffolding for **Capstone engineering quality**:\n",
        "\n",
        "- CLI skeleton (`argparse`)\n",
        "- config loading via environment variables (`.env`)\n",
        "- basic testing patterns (`pytest` and a `smoke_test.py` alternative)\n",
        "\n",
        "## What success looks like (end of practice)\n",
        "\n",
        "- You can point to a CLI skeleton with sensible defaults and clear `--help`.\n",
        "- You can point to a config/secrets pattern that does not hardcode keys.\n",
        "- You add one small TODO exercise and save an artifact under `output/`.\n",
        "\n",
        "### Checkpoint\n",
        "\n",
        "- You can run the TODO cell and see a file written under `output/`.\n",
        "\n",
        "## References (docs)\n",
        "- Python `argparse` (official): https://docs.python.org/3/library/argparse.html\n",
        "- Twelve-Factor App — config: https://12factor.net/config\n",
        "- python-dotenv: https://github.com/theskumar/python-dotenv\n",
        "- pytest docs: https://docs.pytest.org/\n",
        "- Python errors/exceptions: https://docs.python.org/3/tutorial/errors.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Note\n",
        "\n",
        "Jupyter isn’t ideal for building CLIs/tests, but this notebook shows starter code snippets you can copy into:\n",
        "- `analyze.py` (CLI entrypoint)\n",
        "- `src/` modules\n",
        "- `tests/`\n",
        "\n",
        "Use it as a reference while implementing your Capstone repository structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import textwrap\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CLI skeleton (`argparse`)\n",
        "\n",
        "Copy this into `analyze.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cli_skeleton = textwrap.dedent('''\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def build_parser() -> argparse.ArgumentParser:\n",
        "    p = argparse.ArgumentParser(description='Capstone analyzer')\n",
        "    p.add_argument('--input', required=True, help='Path to input CSV')\n",
        "    p.add_argument('--out', default='output', help='Output directory')\n",
        "    return p\n",
        "\n",
        "\n",
        "def main() -> int:\n",
        "    args = build_parser().parse_args()\n",
        "    in_path = Path(args.input)\n",
        "    out_dir = Path(args.out)\n",
        "    out_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # TODO: call your pipeline here\n",
        "    # pipeline_run(in_path, out_dir)\n",
        "\n",
        "    print('OK')\n",
        "    return 0\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    raise SystemExit(main())\n",
        "''')\n",
        "print(cli_skeleton)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Config and secrets (`.env`)\n",
        "\n",
        "In real projects, keep secrets out of code. You can load them from environment variables.\n",
        "\n",
        "Copy pattern into your project and do not commit `.env`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dotenv_pattern = textwrap.dedent('''\n",
        "import os\n",
        "\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "except ModuleNotFoundError:\n",
        "    pass\n",
        "\n",
        "API_KEY = os.getenv('API_KEY')\n",
        "if not API_KEY:\n",
        "    raise RuntimeError('Missing API_KEY. Put it in .env or environment variables.')\n",
        "''')\n",
        "print(dotenv_pattern)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing: pytest starter\n",
        "\n",
        "Copy this into `tests/test_pipeline.py`.\n",
        "\n",
        "The idea is: test normal + edge + failure cases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pytest_example = textwrap.dedent('''\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# from src.pipeline import pipeline_run\n",
        "\n",
        "def test_happy_path(tmp_path: Path):\n",
        "    df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
        "    in_path = tmp_path / 'in.csv'\n",
        "    out_dir = tmp_path / 'out'\n",
        "    df.to_csv(in_path, index=False)\n",
        "\n",
        "    # pipeline_run(in_path, out_dir)\n",
        "    # assert (out_dir / 'report.json').exists()\n",
        "    assert in_path.exists()\n",
        "\n",
        "def test_missing_file(tmp_path: Path):\n",
        "    missing = tmp_path / 'missing.csv'\n",
        "    # with pytest.raises(FileNotFoundError):\n",
        "    #     pipeline_run(missing, tmp_path / 'out')\n",
        "    assert not missing.exists()\n",
        "''')\n",
        "print(pytest_example)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing alternative: `smoke_test.py`\n",
        "\n",
        "If you’re not ready for pytest yet, a smoke test script is acceptable in Level 1 (but pytest is preferred).\n",
        "\n",
        "Copy into `smoke_test.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "smoke_test = textwrap.dedent('''\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "def main() -> int:\n",
        "    tmp = Path('output')\n",
        "    tmp.mkdir(exist_ok=True)\n",
        "\n",
        "    df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
        "    in_path = tmp / 'smoke.csv'\n",
        "    df.to_csv(in_path, index=False)\n",
        "\n",
        "    # TODO: run your pipeline\n",
        "    # pipeline_run(in_path, tmp)\n",
        "\n",
        "    print('SMOKE OK')\n",
        "    return 0\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    raise SystemExit(main())\n",
        "''')\n",
        "print(smoke_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d95b06c5",
      "metadata": {},
      "source": [
        "## Exercise (TODO)\n",
        "\n",
        "Create a minimal `.gitignore` snippet for a capstone repo and save it under `output/`.\n",
        "\n",
        "Goal:\n",
        "\n",
        "- Implement `gitignore_snippet_todo()` to return a string.\n",
        "- Write it to `output/gitignore_snippet.txt`.\n",
        "\n",
        "Checkpoint:\n",
        "\n",
        "- The snippet contains at least: `.env`, `output/`, and `__pycache__/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb7d0f38",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "\n",
        "OUTPUT_DIR = Path(\"output\")\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "\n",
        "def gitignore_snippet_todo() -> str:\n",
        "    # TODO: implement\n",
        "    return \"output/\\n\"\n",
        "\n",
        "\n",
        "snippet = gitignore_snippet_todo()\n",
        "(OUTPUT_DIR / \"gitignore_snippet.txt\").write_text(snippet, encoding=\"utf-8\")\n",
        "print(\"wrote:\", OUTPUT_DIR / \"gitignore_snippet.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6325110",
      "metadata": {},
      "source": [
        "## Appendix: Solutions (peek only after trying)\n",
        "\n",
        "Reference implementation for `gitignore_snippet_todo`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b801f60",
      "metadata": {},
      "outputs": [],
      "source": [
        "def gitignore_snippet_todo() -> str:\n",
        "    lines = [\n",
        "        \".env\",\n",
        "        \"output/\",\n",
        "        \"__pycache__/\",\n",
        "        \"*.pyc\",\n",
        "        \".pytest_cache/\",\n",
        "    ]\n",
        "    return \"\\n\".join(lines) + \"\\n\"\n",
        "\n",
        "\n",
        "snippet = gitignore_snippet_todo()\n",
        "(OUTPUT_DIR / \"gitignore_snippet_solution.txt\").write_text(snippet, encoding=\"utf-8\")\n",
        "print(\"wrote:\", OUTPUT_DIR / \"gitignore_snippet_solution.txt\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
