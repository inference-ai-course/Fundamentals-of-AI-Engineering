{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 — Part 01: From scripts to pipelines (stages + artifacts)\n",
    "\n",
    "**Estimated time:** 75–120 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Define pipeline stages with clear inputs/outputs\n",
    "- Understand how artifacts improve reproducibility and debugging\n",
    "- Design stage contracts (inputs, outputs, invariants)\n",
    "- Implement a simple pipeline skeleton with explicit stages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd27e0dd",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "A pipeline is a sequence of stages.\n",
    "\n",
    "Each stage should have:\n",
    "\n",
    "- clear inputs\n",
    "- clear outputs\n",
    "- a single responsibility\n",
    "\n",
    "This structure improves:\n",
    "\n",
    "- debugging (you can isolate failures)\n",
    "- reproducibility (you save intermediate artifacts)\n",
    "\n",
    "---\n",
    "\n",
    "## Underlying theory: pipelines make dataflow explicit\n",
    "\n",
    "You can view a pipeline as a composition of functions:\n",
    "\n",
    "$$\n",
    "Y = (f_k \\circ f_{k-1} \\circ \\cdots \\circ f_1)(X)\n",
    "$$\n",
    "\n",
    "Each stage should have a small, testable contract:\n",
    "\n",
    "- **inputs**: what files/values it needs\n",
    "- **outputs**: what artifacts it produces\n",
    "- **invariants**: what must be true after it runs (schema, counts, non-empty, etc.)\n",
    "\n",
    "Practical implication:\n",
    "\n",
    "- a bug is easier to locate because you can bisect stages\n",
    "- you can cache/reuse artifacts (don’t redo expensive work unnecessarily)\n",
    "- you can re-run only the stage you changed (faster iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11cfc8a",
   "metadata": {},
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Callable, Any\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Stage:\n",
    "    name: str\n",
    "    run: Callable[[dict], dict]\n",
    "    outputs: list[str]\n",
    "\n",
    "\n",
    "def run_pipeline(stages: list[Stage], context: dict) -> dict:\n",
    "    for stage in stages:\n",
    "        print(f\"running stage: {stage.name}\")\n",
    "        context = stage.run(context)\n",
    "        for key in stage.outputs:\n",
    "            if key not in context:\n",
    "                raise RuntimeError(f\"stage {stage.name} did not produce output: {key}\")\n",
    "    return context\n",
    "\n",
    "\n",
    "# Example stage stubs (replace with real logic)\n",
    "\n",
    "def load_stage(ctx: dict) -> dict:\n",
    "    ctx[\"loaded\"] = \"loaded_table_placeholder\"\n",
    "    return ctx\n",
    "\n",
    "\n",
    "def profile_stage(ctx: dict) -> dict:\n",
    "    ctx[\"profile\"] = {\"rows\": 100, \"cols\": 5}\n",
    "    return ctx\n",
    "\n",
    "\n",
    "def compress_stage(ctx: dict) -> dict:\n",
    "    ctx[\"compressed\"] = {\"sample_rows\": 5}\n",
    "    return ctx\n",
    "\n",
    "\n",
    "def llm_stage(ctx: dict) -> dict:\n",
    "    ctx[\"llm_raw\"] = \"raw text\"\n",
    "    ctx[\"llm_validated\"] = {\"summary\": \"...\"}\n",
    "    return ctx\n",
    "\n",
    "\n",
    "def report_stage(ctx: dict) -> dict:\n",
    "    ctx[\"report\"] = {\"title\": \"Demo Report\"}\n",
    "    return ctx\n",
    "\n",
    "\n",
    "pipeline = [\n",
    "    Stage(\"load\", load_stage, [\"loaded\"]),\n",
    "    Stage(\"profile\", profile_stage, [\"profile\"]),\n",
    "    Stage(\"compress\", compress_stage, [\"compressed\"]),\n",
    "    Stage(\"llm\", llm_stage, [\"llm_raw\", \"llm_validated\"]),\n",
    "    Stage(\"report\", report_stage, [\"report\"]),\n",
    "]\n",
    "\n",
    "final_ctx = run_pipeline(pipeline, {})\n",
    "print(\"final keys:\", sorted(final_ctx.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196b8770",
   "metadata": {},
   "source": [
    "## Suggested capstone stages\n",
    "\n",
    "Make the contract explicit for each stage:\n",
    "\n",
    "1. **Load**\n",
    "   - Inputs: `data/*.csv`\n",
    "   - Outputs: loaded table or `output/loaded.parquet`\n",
    "   - Pitfalls: dtype drift, missing columns, encoding issues\n",
    "\n",
    "2. **Profile**\n",
    "   - Outputs: `output/profile.json` (and optionally `output/profile.md`)\n",
    "\n",
    "3. **Compress**\n",
    "   - Outputs: `output/compressed_input.json`\n",
    "   - Goal: fit key info into the context window\n",
    "\n",
    "4. **LLM**\n",
    "   - Outputs: `output/llm_raw.txt` and `output/llm_validated.json`\n",
    "\n",
    "5. **Report**\n",
    "   - Outputs: `output/report.json` and `output/report.md`\n",
    "\n",
    "Rule of thumb: if a stage fails, you should still have the previous stage’s artifact saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4657a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def write_artifact(path: Path, data: str) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    path.write_text(data, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def stage_with_artifact(name: str, out_path: Path, payload: str) -> dict:\n",
    "    write_artifact(out_path, payload)\n",
    "    return {name: str(out_path)}\n",
    "\n",
    "\n",
    "ctx = {}\n",
    "ctx.update(stage_with_artifact(\"profile\", Path(\"output/profile.json\"), \"{}\"))\n",
    "ctx.update(stage_with_artifact(\"compressed\", Path(\"output/compressed_input.json\"), \"{}\"))\n",
    "print(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868a53bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_stage_outputs(ctx: dict, required: list[str]) -> None:\n",
    "    missing = [k for k in required if k not in ctx]\n",
    "    if missing:\n",
    "        raise ValueError(f\"missing outputs: {missing}\")\n",
    "\n",
    "\n",
    "# TODO: add schema checks (e.g., profile has expected keys)\n",
    "print(\"Implement schema checks in validate_stage_outputs().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f1683e",
   "metadata": {},
   "source": [
    "## Self-check\n",
    "\n",
    "- If the LLM call fails, do you still have the profiling artifact?\n",
    "- Can you re-run only the LLM stage with the saved compressed input?\n",
    "\n",
    "## References\n",
    "\n",
    "- Twelve-Factor logs/config mindset: https://12factor.net/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
