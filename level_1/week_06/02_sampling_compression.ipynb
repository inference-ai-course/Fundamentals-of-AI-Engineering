{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 — Part 02: Sampling and compression for tabular data\n",
    "\n",
    "**Estimated time:** 75–120 minutes\n",
    "\n",
    "## What success looks like (end of Part 02)\n",
    "\n",
    "- You can build a deterministic compressed table representation (same output for same seed).\n",
    "- You can write a bounded JSON artifact suitable for an LLM under `output/`.\n",
    "- You can extend compression with at least one extra summary (numeric stats or top categories).\n",
    "\n",
    "### Checkpoint\n",
    "\n",
    "After running this notebook, you should have:\n",
    "\n",
    "- a printed JSON payload for a `CompressedTable`\n",
    "- an `output/compressed_input.json` file\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Explain why compression is required for large tables\n",
    "- Build a compressed representation (stats + sample rows)\n",
    "- Produce deterministic JSON artifacts for LLM input\n",
    "- Add TODO exercises for improving compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35e22c",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "You usually cannot send a full dataset to an LLM. Instead you send a compressed representation:\n",
    "\n",
    "- descriptive stats\n",
    "- missingness summary\n",
    "- a small sample of rows\n",
    "- detected anomalies\n",
    "\n",
    "---\n",
    "\n",
    "## Underlying theory: you are fitting information into a fixed budget\n",
    "\n",
    "The model has a fixed context window, so your input must satisfy a budget constraint:\n",
    "\n",
    "$$\n",
    "C \\ge T_{\\text{prompt}} + T_{\\text{table}} + T_{\\text{output}}\n",
    "$$\n",
    "\n",
    "If your table is large, $T_{\\text{table}}$ dominates. Compression reduces $T_{\\text{table}}$ by replacing raw rows with summaries.\n",
    "\n",
    "Practical implication: good compression keeps *the facts that matter for the task* while dropping redundant detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe2b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except Exception as e:  # pragma: no cover\n",
    "    pd = None\n",
    "    _pd_import_error = e\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CompressedTable:\n",
    "    shape: Tuple[int, int]\n",
    "    columns: List[str]\n",
    "    dtypes: Dict[str, str]\n",
    "    missing: Dict[str, int]\n",
    "    sample_rows: List[Dict[str, object]]\n",
    "    sample_seed: int\n",
    "\n",
    "\n",
    "def compress_table_v2(df, *, sample_n: int = 6, seed: int = 7) -> CompressedTable:\n",
    "    sample = df.sample(n=min(sample_n, len(df)), random_state=seed) if len(df) > 0 else df\n",
    "    return CompressedTable(\n",
    "        shape=(int(df.shape[0]), int(df.shape[1])),\n",
    "        columns=list(df.columns),\n",
    "        dtypes={c: str(t) for c, t in df.dtypes.to_dict().items()},\n",
    "        missing={c: int(v) for c, v in df.isna().sum().to_dict().items()},\n",
    "        sample_rows=sample.to_dict(orient=\"records\"),\n",
    "        sample_seed=seed,\n",
    "    )\n",
    "\n",
    "\n",
    "def to_json(ct: CompressedTable) -> str:\n",
    "    payload = {\n",
    "        \"shape\": list(ct.shape),\n",
    "        \"columns\": ct.columns,\n",
    "        \"dtypes\": ct.dtypes,\n",
    "        \"missing\": ct.missing,\n",
    "        \"sample_rows\": ct.sample_rows,\n",
    "        \"sample_seed\": ct.sample_seed,\n",
    "    }\n",
    "    return json.dumps(payload, indent=2, sort_keys=True)\n",
    "\n",
    "\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "if pd is None:\n",
    "    print(\"pandas not available:\", _pd_import_error)\n",
    "else:\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"age\": [29, 31, None, 42, 25],\n",
    "            \"city\": [\"NY\", \"LA\", \"LA\", \"SF\", \"NY\"],\n",
    "            \"salary\": [90000, 120000, 95000, None, 70000],\n",
    "        }\n",
    "    )\n",
    "    ct = compress_table_v2(df, sample_n=4, seed=101)\n",
    "    payload_str = to_json(ct)\n",
    "    print(payload_str)\n",
    "    (OUTPUT_DIR / \"compressed_input.json\").write_text(payload_str, encoding=\"utf-8\")\n",
    "    print(\"wrote:\", OUTPUT_DIR / \"compressed_input.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322aa2c4",
   "metadata": {},
   "source": [
    "## Why the design choices matter\n",
    "\n",
    "- sampling uses a `seed` so results are stable across runs\n",
    "- `sort_keys=True` produces deterministic JSON (diff-friendly)\n",
    "- a structured object (`CompressedTable`) makes it easier to evolve the contract later\n",
    "\n",
    "Calibration tip:\n",
    "\n",
    "- start with a small `sample_n` (e.g., 5–10)\n",
    "- if the LLM misses important patterns, add targeted summaries rather than dumping more rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2add60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "\n",
    "def add_numeric_summary(df) -> Dict[str, Any]:\n",
    "    # TODO: add min/mean/max per numeric column.\n",
    "    return {}\n",
    "\n",
    "\n",
    "def add_top_categories(df, top_k: int = 3) -> Dict[str, Any]:\n",
    "    # TODO: compute top categories for object/string columns.\n",
    "    return {}\n",
    "\n",
    "\n",
    "if pd is None:\n",
    "    print(\"pandas not available; skipping exercise cells\")\n",
    "else:\n",
    "    extra = {\n",
    "        \"numeric_summary\": add_numeric_summary(df),\n",
    "        \"top_categories\": add_top_categories(df, top_k=3),\n",
    "    }\n",
    "    (OUTPUT_DIR / \"compressed_extras.json\").write_text(json.dumps(extra, indent=2, sort_keys=True), encoding=\"utf-8\")\n",
    "    print(\"wrote:\", OUTPUT_DIR / \"compressed_extras.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8772f0",
   "metadata": {},
   "source": [
    "## Appendix: Solutions (peek only after trying)\n",
    "\n",
    "Reference implementations for the TODO functions in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f958fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_numeric_summary(df) -> Dict[str, Any]:\n",
    "    numeric = df.select_dtypes(include=\"number\")\n",
    "    out: Dict[str, Any] = {}\n",
    "    if numeric.shape[1] == 0:\n",
    "        return out\n",
    "    for col in numeric.columns:\n",
    "        s = numeric[col].dropna()\n",
    "        if len(s) == 0:\n",
    "            out[str(col)] = {\"min\": None, \"mean\": None, \"max\": None}\n",
    "        else:\n",
    "            out[str(col)] = {\n",
    "                \"min\": float(s.min()),\n",
    "                \"mean\": float(s.mean()),\n",
    "                \"max\": float(s.max()),\n",
    "            }\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_top_categories(df, top_k: int = 3) -> Dict[str, Any]:\n",
    "    obj = df.select_dtypes(include=[\"object\"]) if hasattr(df, \"select_dtypes\") else df\n",
    "    out: Dict[str, Any] = {}\n",
    "    if getattr(obj, \"shape\", (0, 0))[1] == 0:\n",
    "        return out\n",
    "\n",
    "    for col in obj.columns:\n",
    "        vc = obj[col].fillna(\"<NA>\").astype(str).value_counts(dropna=False)\n",
    "        top = vc.head(int(top_k))\n",
    "        out[str(col)] = [{\"value\": str(idx), \"count\": int(cnt)} for idx, cnt in top.items()]\n",
    "    return out\n",
    "\n",
    "\n",
    "if pd is not None:\n",
    "    extra_solution = {\n",
    "        \"numeric_summary\": add_numeric_summary(df),\n",
    "        \"top_categories\": add_top_categories(df, top_k=3),\n",
    "    }\n",
    "    (OUTPUT_DIR / \"compressed_extras_solution.json\").write_text(\n",
    "        json.dumps(extra_solution, indent=2, sort_keys=True),\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "    print(\"wrote:\", OUTPUT_DIR / \"compressed_extras_solution.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
