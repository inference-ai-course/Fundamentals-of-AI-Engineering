{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 — Part 02: Sampling and compression for tabular data\n",
    "\n",
    "**Estimated time:** 75–120 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Explain why compression is required for large tables\n",
    "- Build a compressed representation (stats + sample rows)\n",
    "- Produce deterministic JSON artifacts for LLM input\n",
    "- Add TODO exercises for improving compression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35e22c",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "You usually cannot send a full dataset to an LLM. Instead you send a compressed representation:\n",
    "\n",
    "- descriptive stats\n",
    "- missingness summary\n",
    "- a small sample of rows\n",
    "- detected anomalies\n",
    "\n",
    "---\n",
    "\n",
    "## Underlying theory: you are fitting information into a fixed budget\n",
    "\n",
    "The model has a fixed context window, so your input must satisfy a budget constraint:\n",
    "\n",
    "$$\n",
    "C \\ge T_{\\text{prompt}} + T_{\\text{table}} + T_{\\text{output}}\n",
    "$$\n",
    "\n",
    "If your table is large, $T_{\\text{table}}$ dominates. Compression reduces $T_{\\text{table}}$ by replacing raw rows with summaries.\n",
    "\n",
    "Practical implication: good compression keeps *the facts that matter for the task* while dropping redundant detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe2b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except Exception as e:  # pragma: no cover\n",
    "    pd = None\n",
    "    _pd_import_error = e\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CompressedTable:\n",
    "    shape: tuple[int, int]\n",
    "    columns: list[str]\n",
    "    dtypes: dict[str, str]\n",
    "    missing: dict[str, int]\n",
    "    sample_rows: list[dict]\n",
    "    sample_seed: int\n",
    "\n",
    "\n",
    "def compress_table_v2(df, *, sample_n: int = 6, seed: int = 7) -> CompressedTable:\n",
    "    sample = df.sample(n=min(sample_n, len(df)), random_state=seed) if len(df) > 0 else df\n",
    "    return CompressedTable(\n",
    "        shape=(int(df.shape[0]), int(df.shape[1])),\n",
    "        columns=list(df.columns),\n",
    "        dtypes={c: str(t) for c, t in df.dtypes.to_dict().items()},\n",
    "        missing={c: int(v) for c, v in df.isna().sum().to_dict().items()},\n",
    "        sample_rows=sample.to_dict(orient=\"records\"),\n",
    "        sample_seed=seed,\n",
    "    )\n",
    "\n",
    "\n",
    "def to_json(ct: CompressedTable) -> str:\n",
    "    payload = {\n",
    "        \"shape\": ct.shape,\n",
    "        \"columns\": ct.columns,\n",
    "        \"dtypes\": ct.dtypes,\n",
    "        \"missing\": ct.missing,\n",
    "        \"sample_rows\": ct.sample_rows,\n",
    "        \"sample_seed\": ct.sample_seed,\n",
    "    }\n",
    "    return json.dumps(payload, indent=2, sort_keys=True)\n",
    "\n",
    "\n",
    "if pd is None:\n",
    "    print(\"pandas not available:\", _pd_import_error)\n",
    "else:\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"age\": [29, 31, None, 42, 25],\n",
    "            \"city\": [\"NY\", \"LA\", \"LA\", \"SF\", \"NY\"],\n",
    "            \"salary\": [90000, 120000, 95000, None, 70000],\n",
    "        }\n",
    "    )\n",
    "    ct = compress_table_v2(df, sample_n=4, seed=101)\n",
    "    print(to_json(ct))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322aa2c4",
   "metadata": {},
   "source": [
    "## Why the design choices matter\n",
    "\n",
    "- sampling uses a `seed` so results are stable across runs\n",
    "- `sort_keys=True` produces deterministic JSON (diff-friendly)\n",
    "- a structured object (`CompressedTable`) makes it easier to evolve the contract later\n",
    "\n",
    "Calibration tip:\n",
    "\n",
    "- start with a small `sample_n` (e.g., 5–10)\n",
    "- if the LLM misses important patterns, add targeted summaries rather than dumping more rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2add60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_numeric_summary(df) -> dict:\n",
    "    # TODO: add min/mean/max per numeric column.\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def add_top_categories(df, top_k: int = 3) -> dict:\n",
    "    # TODO: compute top categories for object/string columns.\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "print(\"Implement add_numeric_summary() and add_top_categories().\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
