{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Level 1 — Week 8 Practice (Demo + Retrospective Notebook)\n",
        "\n",
        "This notebook gives you templates for:\n",
        "- a **demo checklist**\n",
        "- a **demo script** (what to show in 5–10 minutes)\n",
        "- a **retrospective / postmortem** write-up\n",
        "\n",
        "## What success looks like (end of practice)\n",
        "\n",
        "- You write at least one demo artifact under `output/` (checklist / demo notes / retrospective).\n",
        "- You can explain your capstone in 5–10 minutes using a stable script.\n",
        "- You have a short failure-case story with evidence.\n",
        "\n",
        "### Checkpoint\n",
        "\n",
        "- `output/DEMO_NOTES.md` exists.\n",
        "\n",
        "## References (docs)\n",
        "- GitHub — About READMEs: https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-readmes\n",
        "- Google SRE — postmortem culture: https://sre.google/sre-book/postmortem-culture/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo checklist (copy into your README or demo notes)\n",
        "\n",
        "- [ ] Fresh environment setup steps are documented and work\n",
        "- [ ] One-command run works (example command + expected outputs)\n",
        "- [ ] Output directory contains `report.json` and `report.md`\n",
        "- [ ] Logs show which stage is running and where failures occur\n",
        "- [ ] At least one failure case is demonstrated with an explainable error\n",
        "- [ ] At least 3 test cases exist (pytest or manual checklist / smoke test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo script (5–10 minutes)\n",
        "\n",
        "1) Problem statement\n",
        "- What dataset type does this handle?\n",
        "- What does the generated report provide?\n",
        "\n",
        "2) Architecture (high level)\n",
        "- Modules/stages (profile -> sample -> LLM -> report)\n",
        "\n",
        "3) Live run (happy path)\n",
        "- Run your one-command entrypoint\n",
        "- Show generated `report.md`\n",
        "- Show `report.json` schema stability\n",
        "\n",
        "4) Failure handling\n",
        "- Run with a missing/invalid CSV and show the error message\n",
        "- Show logs pointing to the stage\n",
        "\n",
        "5) What you’d improve next\n",
        "- Better evaluation\n",
        "- Better sampling/chunking\n",
        "- RAG/agents readiness (Level 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrospective template (copy into `postmortem.md`)\n",
        "\n",
        "### 1) Summary\n",
        "- What did you build?\n",
        "- What is the final user experience?\n",
        "\n",
        "### 2) Top issues encountered (pick 1–3)\n",
        "For each issue:\n",
        "- Symptoms (what you saw)\n",
        "- Root cause (why it happened)\n",
        "- Fix (what you changed)\n",
        "- Prevention (how you’d avoid it next time)\n",
        "\n",
        "### 3) Evidence\n",
        "- Commands you ran\n",
        "- Logs/screenshots (optional)\n",
        "- Before/after behavior\n",
        "\n",
        "### 4) Next steps (Level 2 readiness)\n",
        "- If you were turning this into a RAG assistant, what would you add?\n",
        "  - knowledge base\n",
        "  - retrieval\n",
        "  - evaluation set\n",
        "  - feedback loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Figures (Comprehensive Overviews — Leave Blank)\n",
        "\n",
        "### Figure A: Demo architecture overview\n",
        "\n",
        "\n",
        "### Figure B: Iteration loop (run -> observe -> fix -> re-run)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30feef4f",
      "metadata": {},
      "source": [
        "## Exercise (TODO): write demo notes\n",
        "\n",
        "Write a short demo script (5–10 minutes) tailored to your capstone.\n",
        "\n",
        "Goal:\n",
        "\n",
        "- Implement `demo_notes_todo()`.\n",
        "- Save the result to `output/DEMO_NOTES.md`.\n",
        "\n",
        "Checkpoint:\n",
        "\n",
        "- The file includes a \"Happy path\" section and a \"Failure case\" section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2abaa6a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "\n",
        "OUTPUT_DIR = Path(\"output\")\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "\n",
        "def demo_notes_todo() -> str:\n",
        "    # TODO: customize for your capstone\n",
        "    return \"\\n\".join(\n",
        "        [\n",
        "            \"# Demo Notes\",\n",
        "            \"\",\n",
        "            \"## Happy path\",\n",
        "            \"- <todo: command you run>\",\n",
        "            \"- <todo: artifact you show>\",\n",
        "            \"\",\n",
        "            \"## Failure case\",\n",
        "            \"- <todo: what fails>\",\n",
        "            \"- <todo: evidence (file path/log line)>\",\n",
        "        ]\n",
        "    ) + \"\\n\"\n",
        "\n",
        "\n",
        "out_path = OUTPUT_DIR / \"DEMO_NOTES.md\"\n",
        "out_path.write_text(demo_notes_todo(), encoding=\"utf-8\")\n",
        "print(\"wrote:\", out_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e263b57f",
      "metadata": {},
      "source": [
        "## Appendix: Solutions (peek only after trying)\n",
        "\n",
        "Reference implementation for `demo_notes_todo`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff4179c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def demo_notes_todo() -> str:\n",
        "    return \"\\n\".join(\n",
        "        [\n",
        "            \"# Demo Notes\",\n",
        "            \"\",\n",
        "            \"## Problem statement (15s)\",\n",
        "            \"- This capstone profiles a CSV and produces a stable report (JSON + Markdown).\",\n",
        "            \"\",\n",
        "            \"## Architecture (60s)\",\n",
        "            \"- Stages: load -> profile -> compress -> llm -> report\",\n",
        "            \"- Artifacts under output/: profile.json, compressed_input.json, report.json, report.md\",\n",
        "            \"\",\n",
        "            \"## Happy path (2–3m)\",\n",
        "            \"- Command: python run_capstone.py --input output/capstone_sample.csv --output_dir output --model llama3.1\",\n",
        "            \"- Show: output/report.md (human) and output/report.json (schema)\",\n",
        "            \"\",\n",
        "            \"## Failure case (1m)\",\n",
        "            \"- Command: python run_capstone.py --input missing.csv --output_dir output --model llama3.1\",\n",
        "            \"- Show: actionable error message + (optional) any saved artifact/log\",\n",
        "            \"\",\n",
        "            \"## Next steps (30s)\",\n",
        "            \"- Add eval set + metrics, then add retrieval (Level 2 readiness)\",\n",
        "        ]\n",
        "    ) + \"\\n\"\n",
        "\n",
        "\n",
        "solution_path = OUTPUT_DIR / \"DEMO_NOTES_solution.md\"\n",
        "solution_path.write_text(demo_notes_todo(), encoding=\"utf-8\")\n",
        "print(\"wrote:\", solution_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
