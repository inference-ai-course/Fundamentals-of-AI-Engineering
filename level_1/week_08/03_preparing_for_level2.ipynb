{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 — Part 03: Preparing for Level 2 (what changes)\n",
    "\n",
    "**Estimated time:** 30–45 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Identify the shift from scripts to systems in Level 2\n",
    "- Understand new failure surfaces (retrieval, evaluation, agents)\n",
    "- Capture practical mindset shifts for Level 2 work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c55b96",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Level 1 is mostly:\n",
    "\n",
    "- a single-project pipeline\n",
    "- mostly offline, script-based\n",
    "- focusing on reproducibility and reliability basics\n",
    "\n",
    "Level 2 shifts toward **systems thinking**:\n",
    "\n",
    "- retrieval (RAG)\n",
    "- evaluation loops\n",
    "- multi-step agent workflows\n",
    "- knowledge bases\n",
    "\n",
    "---\n",
    "\n",
    "## Underlying theory: Level 2 adds feedback loops and new failure surfaces\n",
    "\n",
    "In Level 1, many workflows are “run once and inspect outputs”.\n",
    "\n",
    "In Level 2, you build systems with feedback loops:\n",
    "\n",
    "- retrieval quality affects generation quality\n",
    "- evaluation metrics guide iteration\n",
    "- multi-step workflows introduce compounding failure probability\n",
    "\n",
    "Practical implication:\n",
    "\n",
    "- you need observability (traces/logs) to debug why a system answered\n",
    "- you need eval sets to prevent “prompt overfitting”\n",
    "- you need trust boundaries to resist prompt injection when external data is involved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064e890c",
   "metadata": {},
   "source": [
    "## Practical mindset shifts\n",
    "\n",
    "- From “one script works” → “the system is observable and testable”.\n",
    "- From “prompting” → “prompt + retrieval + evaluation”.\n",
    "- From “manual checking” → “repeatable eval sets”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a7f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level2_self_check() -> list[str]:\n",
    "    # TODO: add your own readiness checklist.\n",
    "    return [\n",
    "        \"I can explain what RAG is and why it helps.\",\n",
    "        \"I know how to build a small evaluation set.\",\n",
    "        \"I understand prompt injection risk in retrieval systems.\",\n",
    "    ]\n",
    "\n",
    "\n",
    "print(\"Level 2 self-check:\")\n",
    "for item in level2_self_check():\n",
    "    print(\"-\", item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1eb00e",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- RAG overview: https://www.pinecone.io/learn/retrieval-augmented-generation/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc2408",
   "metadata": {},
   "source": [
    "## Self-check\n",
    "\n",
    "- Can you explain how retrieval quality affects generation quality?\n",
    "- Do you have a plan for eval sets and metrics?\n",
    "- Do you know how to handle prompt injection risks?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
