{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 — Part 03: Structured outputs (JSON) — parse + validate + retry/repair\n",
    "\n",
    "**Estimated time:** 90–120 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Pre-study (Level 0)\n",
    "\n",
    "Level 1 assumes Level 0 is complete. If you need a refresher on structured outputs, schemas, and validation mindset:\n",
    "\n",
    "- [Level 1 Pre-study index](../PRESTUDY.md)\n",
    "- [Level 0 — Structured outputs and schemas](../../level_0/Chapters/3/01_function_calling_structured_outputs.md)\n",
    "\n",
    "---\n",
    "\n",
    "## What success looks like (end of Part 03)\n",
    "\n",
    "- You can take raw model text and deterministically produce either:\n",
    "  - a validated dict that matches your schema, or\n",
    "  - a clear error with the raw output saved for debugging.\n",
    "- You can run a capped retry/repair loop.\n",
    "\n",
    "### Checkpoint\n",
    "\n",
    "- You can demonstrate at least one failure case (bad JSON or wrong schema) and you saved the raw output under `output/`.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Parse model text into JSON safely\n",
    "- Validate schema and separate parse vs schema failures\n",
    "- Implement a capped retry/repair loop\n",
    "- Save raw outputs for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf92eb",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Models can produce valid JSON, or almost-JSON (extra prose, single quotes, trailing commas).\n",
    "\n",
    "This lab builds a deterministic wrapper:\n",
    "\n",
    "1. ask for strict JSON\n",
    "2. parse it\n",
    "3. validate schema\n",
    "4. retry/repair on failure (capped)\n",
    "\n",
    "Key habit: save raw output when parsing/validation fails so debugging is inspection, not guesswork.\n",
    "\n",
    "If you need more background on schemas/validation, use the Level 0 links at the top of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc696f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def parse_json_strict(text: str) -> dict:\n",
    "    data = json.loads(text)\n",
    "    if not isinstance(data, dict):\n",
    "        raise ValueError(\"expected a JSON object\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def validate_shape(data: dict) -> None:\n",
    "    allowed = {\"person\", \"company\"}\n",
    "    extra = set(data.keys()) - allowed\n",
    "    missing = allowed - set(data.keys())\n",
    "    if missing:\n",
    "        raise ValueError(f\"missing keys: {sorted(missing)}\")\n",
    "    if extra:\n",
    "        raise ValueError(f\"extra keys: {sorted(extra)}\")\n",
    "\n",
    "    for k in [\"person\", \"company\"]:\n",
    "        v = data[k]\n",
    "        if v is not None and not isinstance(v, str):\n",
    "            raise ValueError(f\"{k} must be string or null\")\n",
    "\n",
    "\n",
    "print(validate_shape(parse_json_strict('{\"person\": \"Ada\", \"company\": null}')))\n",
    "\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb814a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_validate(text: str) -> dict:\n",
    "    data = parse_json_strict(text)\n",
    "    validate_shape(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "bad_outputs = [\n",
    "    \"Here is the JSON: {\\\"person\\\": \\\"Ada\\\", \\\"company\\\": null}\",\n",
    "    \"{'person': 'Ada', 'company': null}\",\n",
    "    '{\"person\": \"Ada\"}',\n",
    "]\n",
    "\n",
    "for raw in bad_outputs:\n",
    "    try:\n",
    "        parse_and_validate(raw)\n",
    "        print(\"OK\", raw)\n",
    "    except Exception as e:\n",
    "        print(\"FAIL\", type(e).__name__, \"->\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771dd89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm_stub(prompt: str) -> str:\n",
    "    # Simulate a model that sometimes returns almost-JSON.\n",
    "    if \"REPAIR\" in prompt:\n",
    "        return '{\"person\": \"Ada Lovelace\", \"company\": null}'\n",
    "    return \"Here is the JSON: {\\\"person\\\": \\\"Ada Lovelace\\\", \\\"company\\\": null}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af3eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_with_repair(text: str, call_llm, *, max_retries: int = 2) -> dict:\n",
    "    base_prompt = (\n",
    "        \"Return ONLY JSON with keys person, company (null when unknown).\\n\"\n",
    "        f\"INPUT:\\n{text}\\n\"\n",
    "    )\n",
    "\n",
    "    prompt = base_prompt\n",
    "    last_err = None\n",
    "    for attempt in range(max_retries + 1):\n",
    "        raw = call_llm(prompt)\n",
    "        try:\n",
    "            return parse_and_validate(raw)\n",
    "        except Exception as e:\n",
    "            last_err = str(e)\n",
    "            prompt = (\n",
    "                \"REPAIR: Your previous output was invalid.\\n\"\n",
    "                \"Return ONLY JSON with keys person, company.\\n\"\n",
    "                f\"Invalid output:\\n{raw}\\n\\n\"\n",
    "                f\"Error:\\n{last_err}\\n\"\n",
    "            )\n",
    "\n",
    "    raise ValueError(f\"Failed after retries. Last error: {last_err}\")\n",
    "\n",
    "\n",
    "print(extract_with_repair(\"Ada Lovelace\", call_llm_stub, max_retries=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad43f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_with_repair_todo(text: str, call_llm, *, max_retries: int = 2) -> dict:\n",
    "    # TODO:\n",
    "    # - Add raw-output persistence to output/llm_raw.txt on failure.\n",
    "    # - Separate parse failures from schema failures in the error message.\n",
    "    # - Keep retries capped (max_retries).\n",
    "    return extract_with_repair(text, call_llm, max_retries=max_retries)\n",
    "\n",
    "\n",
    "print(\"Implement extract_with_repair_todo().\")\n",
    "print(extract_with_repair_todo(\"Ada Lovelace\", call_llm_stub, max_retries=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d01db5",
   "metadata": {},
   "source": [
    "## Common pitfalls\n",
    "\n",
    "- Asking for JSON but not banning extra text\n",
    "- Not separating parse failure vs schema failure\n",
    "- No retry cap\n",
    "- Mixing business logic with parsing/validation\n",
    "\n",
    "## References\n",
    "\n",
    "- Python `json`: https://docs.python.org/3/library/json.html\n",
    "- Pydantic (optional): https://docs.pydantic.dev/latest/\n",
    "- JSON Schema: https://json-schema.org/\n",
    "- Tenacity: https://tenacity.readthedocs.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba78a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_validate(text: str) -> dict:\n",
    "    data = parse_json_strict(text)\n",
    "    validate_shape(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "bad_outputs = [\n",
    "    \"Here is the JSON: {\\\"person\\\": \\\"Ada\\\", \\\"company\\\": null}\",\n",
    "    \"{'person': 'Ada', 'company': null}\",\n",
    "    '{\"person\": \"Ada\"}',\n",
    "]\n",
    "\n",
    "for raw in bad_outputs:\n",
    "    try:\n",
    "        parse_and_validate(raw)\n",
    "        print(\"OK\", raw)\n",
    "    except Exception as e:\n",
    "        print(\"FAIL\", type(e).__name__, \"->\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c56b1c0",
   "metadata": {},
   "source": [
    "## Appendix: Solutions (peek only after trying)\n",
    "\n",
    "Reference implementation for `extract_with_repair_todo` that persists raw outputs and clarifies error stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd72104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_with_repair_todo(text: str, call_llm, *, max_retries: int = 2) -> dict:\n",
    "    base_prompt = (\n",
    "        \"Return ONLY JSON with keys person, company (null when unknown).\\n\"\n",
    "        f\"INPUT:\\n{text}\\n\"\n",
    "    )\n",
    "\n",
    "    prompt = base_prompt\n",
    "    last_err = None\n",
    "    last_raw = None\n",
    "\n",
    "    for attempt in range(max_retries + 1):\n",
    "        raw = call_llm(prompt)\n",
    "        last_raw = raw\n",
    "        try:\n",
    "            data = parse_json_strict(raw)\n",
    "        except Exception as e:\n",
    "            last_err = f\"PARSE_ERROR: {e}\"\n",
    "            prompt = (\n",
    "                \"REPAIR: Your previous output was invalid JSON.\\n\"\n",
    "                \"Return ONLY JSON with keys person, company.\\n\"\n",
    "                f\"Invalid output:\\n{raw}\\n\\n\"\n",
    "                f\"Error:\\n{last_err}\\n\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            validate_shape(data)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            last_err = f\"SCHEMA_ERROR: {e}\"\n",
    "            prompt = (\n",
    "                \"REPAIR: Your previous output failed schema validation.\\n\"\n",
    "                \"Return ONLY JSON with keys person, company.\\n\"\n",
    "                f\"Invalid output:\\n{raw}\\n\\n\"\n",
    "                f\"Error:\\n{last_err}\\n\"\n",
    "            )\n",
    "\n",
    "    raw_path = OUTPUT_DIR / \"llm_raw.txt\"\n",
    "    raw_path.write_text(last_raw or \"\", encoding=\"utf-8\")\n",
    "    raise ValueError(f\"Failed after retries. {last_err}. Raw saved to {raw_path}\")\n",
    "\n",
    "\n",
    "try:\n",
    "    extract_with_repair_todo(\"Ada Lovelace\", call_llm_stub, max_retries=1)\n",
    "except Exception as e:\n",
    "    print(\"expected failure path exercised:\", str(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
