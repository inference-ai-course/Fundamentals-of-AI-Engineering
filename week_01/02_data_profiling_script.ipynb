{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 — Part 02: Data profiling script (CSV → JSON/Markdown)\n",
    "\n",
    "**Estimated time:** 90–120 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Treat real-world CSV data as untrusted input\n",
    "- Build a deterministic profiling artifact (`profile.json` + `profile.md`)\n",
    "- Fail fast with clear errors for missing/empty inputs\n",
    "- Add optional schema/required-column checks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84523fca",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In AI/ML/LLM projects, most pain starts with data issues:\n",
    "\n",
    "- wrong column names\n",
    "- unexpected types\n",
    "- empty files\n",
    "- missing values\n",
    "\n",
    "A data profiling script makes these issues visible early.\n",
    "\n",
    "---\n",
    "\n",
    "## Pre-study (Self-learn)\n",
    "\n",
    "Foundamental Course assumes Self-learn is complete. If you need a refresher on modules, exceptions, file I/O, or JSON:\n",
    "\n",
    "- [Foundamental Course Pre-study index](../PRESTUDY.md)\n",
    "- [Self-learn — Modules and exception handling](../self_learn/Chapters/2/02_modules_exceptions.md)\n",
    "\n",
    "---\n",
    "\n",
    "## What success looks like (end of Part 02)\n",
    "\n",
    "Given the same input CSV, your code should always produce:\n",
    "\n",
    "- `output/profile.json` (machine-readable)\n",
    "- `output/profile.md` (human-readable)\n",
    "\n",
    "And it should fail with clear errors for:\n",
    "\n",
    "- missing file\n",
    "- empty file\n",
    "- missing required columns (optional extension)\n",
    "\n",
    "### Checkpoint\n",
    "\n",
    "After you run the notebook end-to-end, you should see `output/profile.json` and `output/profile.md` on disk.\n",
    "\n",
    "Key reproducibility detail: keep outputs deterministic so diffs are meaningful.\n",
    "\n",
    "---\n",
    "\n",
    "## Output contract (recap)\n",
    "\n",
    "Given the same input CSV, the script should always produce:\n",
    "\n",
    "- `output/profile.json`\n",
    "- `output/profile.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42db880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import asdict, dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except Exception as e:  # pragma: no cover\n",
    "    pd = None\n",
    "    _pd_import_error = e\n",
    "\n",
    "\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Profile:\n",
    "    rows: int\n",
    "    cols: int\n",
    "    columns: List[str]\n",
    "    dtypes: Dict[str, str]\n",
    "    missing_by_column: Dict[str, int]\n",
    "\n",
    "\n",
    "def load_csv(path: Path):\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(\"Input file not found: %s\" % path)\n",
    "    if path.stat().st_size == 0:\n",
    "        raise ValueError(\"Input file is empty: %s\" % path)\n",
    "    if pd is None:\n",
    "        raise RuntimeError(\"pandas is required: %s\" % _pd_import_error)\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "def make_profile(df) -> Profile:\n",
    "    missing = df.isna().sum().to_dict()\n",
    "    dtypes = {col: str(dtype) for col, dtype in df.dtypes.to_dict().items()}\n",
    "    return Profile(\n",
    "        rows=int(df.shape[0]),\n",
    "        cols=int(df.shape[1]),\n",
    "        columns=list(df.columns),\n",
    "        dtypes=dtypes,\n",
    "        missing_by_column={k: int(v) for k, v in missing.items()},\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b32ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small sample CSV for profiling (non-verbatim example)\n",
    "if pd is not None:\n",
    "    sample_path = OUTPUT_DIR / \"sample_profile.csv\"\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"user_id\": [1, 2, 3, 4],\n",
    "            \"age\": [22, None, 35, 29],\n",
    "            \"country\": [\"US\", \"SG\", None, \"US\"],\n",
    "        }\n",
    "    )\n",
    "    df.to_csv(sample_path, index=False)\n",
    "    print(\"wrote sample:\", sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a1a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_to_markdown(p: Profile) -> str:\n",
    "    lines = []\n",
    "    lines.append(\"# Data Profile\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(f\"- Rows: {p.rows}\")\n",
    "    lines.append(f\"- Columns: {p.cols}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"## Columns\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"| column | dtype | missing |\")\n",
    "    lines.append(\"|---|---|---:|\")\n",
    "    for col in p.columns:\n",
    "        lines.append(f\"| {col} | {p.dtypes.get(col, '')} | {p.missing_by_column.get(col, 0)} |\")\n",
    "    lines.append(\"\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "if pd is not None:\n",
    "    df2 = load_csv(sample_path)\n",
    "    p = make_profile(df2)\n",
    "    (OUTPUT_DIR / \"profile.json\").write_text(json.dumps(asdict(p), indent=2, sort_keys=True), encoding=\"utf-8\")\n",
    "    (OUTPUT_DIR / \"profile.md\").write_text(profile_to_markdown(p), encoding=\"utf-8\")\n",
    "    print(\"wrote:\", OUTPUT_DIR / \"profile.json\")\n",
    "    print(\"wrote:\", OUTPUT_DIR / \"profile.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba15cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "\n",
    "def require_columns(df, required: List[str]) -> None:\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(\"Missing required columns: %s\" % missing)\n",
    "\n",
    "\n",
    "def numeric_summary_todo(df) -> Dict[str, Any]:\n",
    "    # TODO: implement basic numeric summaries (mean/min/max) per numeric column.\n",
    "    # Hint: df.select_dtypes(include='number').describe().to_dict() is a good starting point.\n",
    "    return {}\n",
    "\n",
    "\n",
    "print(\"TODO: extend with required columns + numeric summaries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28308b7",
   "metadata": {},
   "source": [
    "## Appendix: Solutions (peek only after trying)\n",
    "\n",
    "Reference implementation for the numeric summaries extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1182ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_summary_todo(df) -> dict:\n",
    "    if pd is None:\n",
    "        raise RuntimeError(f\"pandas is required: {_pd_import_error}\")\n",
    "    return df.select_dtypes(include='number').describe().to_dict()\n",
    "\n",
    "\n",
    "if pd is not None:\n",
    "    df2 = load_csv(sample_path)\n",
    "    print(list(numeric_summary_todo(df2).keys())[:5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
