{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Function Calling and Structured Outputs\n",
    "\n",
    "## Welcome to AI That Actually Does Things! üöÄ\n",
    "\n",
    "**What you're about to build:** AI systems that don't just talk‚Äîthey take action.\n",
    "\n",
    "### The Transformation\n",
    "\n",
    "**Traditional AI Interaction:**\n",
    "```\n",
    "You: \"What's the weather?\"\n",
    "AI: \"I don't have access to real-time weather data...\"\n",
    "‚Üí Conversational but useless\n",
    "```\n",
    "\n",
    "**Function-Calling AI (What You'll Build):**\n",
    "```\n",
    "You: \"What's the weather?\"\n",
    "AI: [Calls get_weather(\"Seattle\")]\n",
    "API: {\"temp\": 52, \"condition\": \"Cloudy\"}\n",
    "AI: \"It's currently 52¬∞F and cloudy in Seattle.\"\n",
    "‚Üí Actionable and accurate!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## What Makes This Revolutionary?\n",
    "\n",
    "1. **Real Actions**: AI can check databases, call APIs, control systems\n",
    "2. **Structured Data**: No more parsing unreliable text‚Äîget JSON you can trust\n",
    "3. **Cross-Platform**: Same code works with OpenAI, HuggingFace, Ollama, vLLM\n",
    "4. **Production-Ready**: Built-in validation, error handling, retry logic\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you'll be able to:\n",
    "\n",
    "- ‚úÖ **Implement** function calling with JSON Schema validation\n",
    "- ‚úÖ **Create** structured output generators with constraints\n",
    "- ‚úÖ **Build** cross-platform solutions (OpenAI, HuggingFace, Ollama)\n",
    "- ‚úÖ **Evaluate** different AI providers systematically\n",
    "- ‚úÖ **Handle** errors and edge cases gracefully\n",
    "- ‚úÖ **Deploy** production-ready function calling systems\n",
    "\n",
    "---\n",
    "\n",
    "## Lab Structure\n",
    "\n",
    "**Part 1:** Coffee Recipe Bot (Basic Function Calling)\n",
    "- Simple function definitions\n",
    "- Understanding JSON Schema\n",
    "- First function call\n",
    "\n",
    "**Part 2:** Multi-Provider Integration\n",
    "- OpenAI implementation\n",
    "- HuggingFace alternative\n",
    "- Local Ollama setup\n",
    "\n",
    "**Part 3:** Production Patterns\n",
    "- Validation and error handling\n",
    "- Provider comparison framework\n",
    "- Retry logic and failover\n",
    "\n",
    "**Part 4:** Final Project\n",
    "- Complete game character generator\n",
    "- Multi-provider support\n",
    "- Robust validation\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "**You'll need:**\n",
    "- Python 3.10+ installed\n",
    "- A code editor or Jupyter environment\n",
    "- (Optional) API keys for testing cloud providers\n",
    "- (Optional) Ollama for local testing\n",
    "\n",
    "**Estimated time:** 2-3 hours\n",
    "\n",
    "Let's begin! üí™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai huggingface_hub transformers jsonschema requests python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "Let's start by setting up our environment and API credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from typing import Dict, Any, List, Optional\n",
    "from jsonschema import validate, ValidationError\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# API Keys (use environment variables in production)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"your-openai-key-here\")\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\", \"your-huggingface-token-here\")\n",
    "\n",
    "print(\"Environment setup complete!\")\n",
    "print(f\"OpenAI API Key configured: {'Yes' if OPENAI_API_KEY != 'your-openai-key-here' else 'No'}\")\n",
    "print(f\"HuggingFace Token configured: {'Yes' if HF_TOKEN != 'your-huggingface-token-here' else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Basic Function Calling Setup\n",
    "\n",
    "### Understanding the Components\n",
    "\n",
    "Before diving into code, let's understand what we're building:\n",
    "\n",
    "**1. Function Implementations (Your Python Code)**\n",
    "```python\n",
    "def make_coffee(coffee_type: str) -> Dict[str, Any]:\n",
    "    # This is YOUR code that actually executes\n",
    "    # AI models never run this‚Äîthey just tell YOU to run it\n",
    "```\n",
    "\n",
    "**2. Function Schemas (AI's Instructions)**\n",
    "```json\n",
    "{\n",
    "  \"name\": \"make_coffee\",\n",
    "  \"parameters\": { ... }\n",
    "}\n",
    "```\n",
    "This tells the AI:\n",
    "- What functions exist\n",
    "- What parameters they need\n",
    "- What values are valid\n",
    "\n",
    "**3. The Flow**\n",
    "```\n",
    "User ‚Üí AI analyzes ‚Üí AI generates function call ‚Üí Your code executes ‚Üí Result ‚Üí AI responds\n",
    "```\n",
    "\n",
    "Let's build it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our function implementations\n",
    "def make_coffee(coffee_type: str) -> Dict[str, Any]:\n",
    "    \"\"\"Generate a coffee recipe based on type.\"\"\"\n",
    "    recipes = {\n",
    "        \"espresso\": {\n",
    "            \"coffee_grams\": 18,\n",
    "            \"water_ml\": 36,\n",
    "            \"brew_time_seconds\": 25,\n",
    "            \"temperature_celsius\": 93,\n",
    "            \"pressure_bar\": 9\n",
    "        },\n",
    "        \"cappuccino\": {\n",
    "            \"coffee_grams\": 18,\n",
    "            \"water_ml\": 36,\n",
    "            \"milk_ml\": 120,\n",
    "            \"milk_foam\": \"thick\",\n",
    "            \"brew_time_seconds\": 25\n",
    "        },\n",
    "        \"latte\": {\n",
    "            \"coffee_grams\": 18,\n",
    "            \"water_ml\": 36,\n",
    "            \"milk_ml\": 240,\n",
    "            \"milk_foam\": \"thin\",\n",
    "            \"brew_time_seconds\": 25\n",
    "        },\n",
    "        \"americano\": {\n",
    "            \"coffee_grams\": 18,\n",
    "            \"water_ml\": 36,\n",
    "            \"additional_water_ml\": 120,\n",
    "            \"brew_time_seconds\": 25\n",
    "        }\n",
    "    }\n",
    "    return recipes.get(coffee_type, {\"error\": \"Recipe not found\"})\n",
    "\n",
    "def random_coffee_fact() -> Dict[str, Any]:\n",
    "    \"\"\"Return a random coffee fact.\"\"\"\n",
    "    facts = [\n",
    "        {\"fact\": \"Coffee was first discovered in Ethiopia around 850 AD\", \"source\": \"Historical records\"},\n",
    "        {\"fact\": \"Espresso means 'pressed out' in Italian\", \"source\": \"Italian etymology\"},\n",
    "        {\"fact\": \"Coffee is the world's second-most traded commodity after oil\", \"source\": \"Commodity markets\"},\n",
    "        {\"fact\": \"The average American consumes 3.1 cups of coffee per day\", \"source\": \"National Coffee Association\"},\n",
    "        {\"fact\": \"Coffee beans are actually seeds from coffee cherries\", \"source\": \"Botanical classification\"}\n",
    "    ]\n",
    "    return random.choice(facts)\n",
    "\n",
    "# Define tool schemas for the AI model\n",
    "coffee_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"make_coffee\",\n",
    "            \"description\": \"Generate a coffee recipe for the specified type\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"coffee_type\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"espresso\", \"cappuccino\", \"latte\", \"americano\"],\n",
    "                        \"description\": \"Type of coffee to make\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"coffee_type\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"random_coffee_fact\",\n",
    "            \"description\": \"Get a random interesting fact about coffee\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Function definitions created!\")\n",
    "print(f\"Available tools: {[tool['function']['name'] for tool in coffee_tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: OpenAI Function Calling Implementation\n",
    "\n",
    "### Understanding OpenAI's Function Calling Architecture\n",
    "\n",
    "**The Core Mechanism:**\n",
    "\n",
    "OpenAI's function calling works through a **multi-turn conversation pattern**:\n",
    "\n",
    "1. **Initial Request**: You send messages + function definitions (tools)\n",
    "2. **Model Decision**: AI analyzes the request and decides if/when to call functions\n",
    "3. **Function Execution**: Your code runs the actual function\n",
    "4. **Response Integration**: Function results are sent back to the model\n",
    "5. **Final Answer**: Model synthesizes everything into a natural response\n",
    "\n",
    "**Why This Design?**\n",
    "\n",
    "- **Separation of Concerns**: AI decides WHAT to do, your code does HOW\n",
    "- **Safety**: AI never executes code directly‚Äîyou control all execution\n",
    "- **Flexibility**: Same AI can work with any functions you define\n",
    "- **Reliability**: You validate inputs/outputs before execution\n",
    "\n",
    "---\n",
    "\n",
    "### The Implementation Flow\n",
    "\n",
    "**Step 1: Define Tools (Function Schemas)**\n",
    "```python\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"make_coffee\",\n",
    "        \"parameters\": {...}  # JSON Schema\n",
    "    }\n",
    "}]\n",
    "```\n",
    "This tells the AI: \"You have access to a function called `make_coffee` with these parameters.\"\n",
    "\n",
    "**Step 2: Send Request with Tools**\n",
    "```python\n",
    "response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    tools=tools,  # AI now knows about your functions\n",
    "    tool_choice=\"auto\"  # Let AI decide when to use tools\n",
    ")\n",
    "```\n",
    "\n",
    "**Step 3: Check for Function Calls**\n",
    "```python\n",
    "if response_message.tool_calls:\n",
    "    # AI wants to call a function!\n",
    "    for tool_call in response_message.tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        # Execute your actual function\n",
    "        result = make_coffee(**function_args)\n",
    "```\n",
    "\n",
    "**Step 4: Send Results Back**\n",
    "```python\n",
    "messages.append({\n",
    "    \"role\": \"tool\",\n",
    "    \"tool_call_id\": tool_call.id,\n",
    "    \"content\": json.dumps(result)\n",
    "})\n",
    "```\n",
    "\n",
    "**Step 5: Get Final Response**\n",
    "```python\n",
    "final_response = client.chat.completions.create(\n",
    "    messages=messages  # Now includes function results\n",
    ")\n",
    "# AI synthesizes: \"Here's your cappuccino recipe: ...\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**`tool_choice` Parameter:**\n",
    "- `\"auto\"`: AI decides when to use tools (recommended)\n",
    "- `\"none\"`: AI never uses tools (pure chat)\n",
    "- `{\"type\": \"function\", \"function\": {\"name\": \"make_coffee\"}}`: Force specific function\n",
    "\n",
    "**Tool Call IDs:**\n",
    "- Each function call gets a unique ID\n",
    "- You must match response to the correct call using `tool_call_id`\n",
    "- Enables parallel function calls\n",
    "\n",
    "**Message Roles:**\n",
    "- `\"user\"`: User input\n",
    "- `\"assistant\"`: AI responses\n",
    "- `\"system\"`: System instructions\n",
    "- `\"tool\"`: Function execution results (NEW!)\n",
    "\n",
    "Now let's implement it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    # Initialize OpenAI client\n",
    "    openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    def handle_openai_function_call(messages, tools):\n",
    "        \"\"\"Handle function calling with OpenAI API.\"\"\"\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\"\n",
    "        )\n",
    "        \n",
    "        response_message = response.choices[0].message\n",
    "        \n",
    "        # Check if the model wants to call a function\n",
    "        if response_message.tool_calls:\n",
    "            messages.append(response_message)\n",
    "            \n",
    "            # Handle each function call\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                print(f\"Calling function: {function_name}\")\n",
    "                print(f\"Arguments: {function_args}\")\n",
    "                \n",
    "                # Call the actual function\n",
    "                if function_name == \"make_coffee\":\n",
    "                    function_response = make_coffee(**function_args)\n",
    "                elif function_name == \"random_coffee_fact\":\n",
    "                    function_response = random_coffee_fact()\n",
    "                else:\n",
    "                    function_response = {\"error\": f\"Unknown function: {function_name}\"}\n",
    "                \n",
    "                # Add function response to messages\n",
    "                messages.append({\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": json.dumps(function_response)\n",
    "                })\n",
    "            \n",
    "            # Get final response from model\n",
    "            final_response = openai_client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=messages\n",
    "            )\n",
    "            \n",
    "            return final_response.choices[0].message.content\n",
    "        \n",
    "        return response_message.content\n",
    "    \n",
    "    # Test the function calling\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful coffee assistant. Use the available tools to help users with coffee-related questions.\"},\n",
    "        {\"role\": \"user\", \"content\": \"I'd like to make a cappuccino. Can you give me the recipe?\"}\n",
    "    ]\n",
    "    \n",
    "    result = handle_openai_function_call(messages, coffee_tools)\n",
    "    print(\"\\nFinal response:\")\n",
    "    print(result)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"OpenAI library not installed. Skipping this exercise.\")\n",
    "except Exception as e:\n",
    "    print(f\"OpenAI API error: {e}\")\n",
    "    print(\"Skipping OpenAI exercise. Proceeding with HuggingFace alternatives.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: HuggingFace Implementation\n",
    "\n",
    "### Why HuggingFace? Understanding Open-Source Alternatives\n",
    "\n",
    "**The Challenge with HuggingFace:**\n",
    "\n",
    "Unlike OpenAI, HuggingFace models **don't have built-in function calling**. We need to:\n",
    "1. **Prompt Engineering**: Instruct the model to output structured function calls\n",
    "2. **Response Parsing**: Extract function calls from natural language responses\n",
    "3. **Manual Orchestration**: Handle the conversation flow ourselves\n",
    "\n",
    "**Why This Matters:**\n",
    "\n",
    "- **Cost**: HuggingFace can be free or much cheaper\n",
    "- **Privacy**: Run models locally or on your own infrastructure\n",
    "- **Flexibility**: Use any open-source model\n",
    "- **Learning**: Understand how function calling works under the hood\n",
    "\n",
    "---\n",
    "\n",
    "### The HuggingFace Approach: Prompt-Based Function Calling\n",
    "\n",
    "**Key Difference:**\n",
    "\n",
    "| OpenAI | HuggingFace |\n",
    "|--------|-------------|\n",
    "| Built-in function calling | Manual prompt engineering |\n",
    "| Structured tool_calls response | Natural language with parsing |\n",
    "| Automatic orchestration | Manual conversation management |\n",
    "\n",
    "**Our Strategy:**\n",
    "\n",
    "1. **Structured Prompt**: Tell the model exactly how to format function calls\n",
    "2. **Pattern Matching**: Parse responses to extract function calls\n",
    "3. **Manual Execution**: Run functions and format results\n",
    "4. **Follow-up Prompt**: Send results back and ask for final answer\n",
    "\n",
    "---\n",
    "\n",
    "### Implementation Pattern\n",
    "\n",
    "**Step 1: Create Structured Prompt**\n",
    "```python\n",
    "prompt = f\"\"\"\n",
    "You have access to these tools:\n",
    "- make_coffee(coffee_type): {description}\n",
    "- random_coffee_fact(): {description}\n",
    "\n",
    "If you need to use a tool, respond with:\n",
    "TOOL_CALL: {{\"name\": \"tool_name\", \"arguments\": {{\"param\": \"value\"}}}}\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Why This Format?**\n",
    "- **Explicit**: Model knows exactly what format to use\n",
    "- **Parseable**: Easy to extract with regex/string matching\n",
    "- **Flexible**: Works with any model that can follow instructions\n",
    "\n",
    "**Step 2: Parse Response**\n",
    "```python\n",
    "if \"TOOL_CALL:\" in response_text:\n",
    "    # Extract JSON after TOOL_CALL:\n",
    "    json_str = response_text.split(\"TOOL_CALL:\")[1].strip()\n",
    "    tool_call = json.loads(json_str)\n",
    "```\n",
    "\n",
    "**Step 3: Execute Function**\n",
    "```python\n",
    "function_name = tool_call['name']\n",
    "function_args = tool_call['arguments']\n",
    "result = available_functions[function_name](**function_args)\n",
    "```\n",
    "\n",
    "**Step 4: Follow-up Prompt**\n",
    "```python\n",
    "follow_up = f\"\"\"\n",
    "User asked: {original_query}\n",
    "Function result: {json.dumps(result)}\n",
    "\n",
    "Provide a natural response based on this result.\n",
    "\"\"\"\n",
    "final_response = model.generate(follow_up)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Challenges and Solutions\n",
    "\n",
    "**Challenge 1: Model Doesn't Follow Format**\n",
    "- **Solution**: Use few-shot examples in prompt\n",
    "- **Solution**: Lower temperature for more deterministic output\n",
    "- **Solution**: Post-process to fix common formatting errors\n",
    "\n",
    "**Challenge 2: Invalid JSON in Response**\n",
    "- **Solution**: Use regex to extract JSON-like structures\n",
    "- **Solution**: Try multiple parsing strategies\n",
    "- **Solution**: Fallback to error message if parsing fails\n",
    "\n",
    "**Challenge 3: Model Calls Wrong Function**\n",
    "- **Solution**: Validate function name exists before calling\n",
    "- **Solution**: Provide clear function descriptions\n",
    "- **Solution**: Use examples showing correct usage\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use HuggingFace vs OpenAI\n",
    "\n",
    "**Use HuggingFace When:**\n",
    "- ‚úÖ Cost is a primary concern\n",
    "- ‚úÖ Data privacy is critical (local deployment)\n",
    "- ‚úÖ You need to customize model behavior\n",
    "- ‚úÖ You want to understand the internals\n",
    "\n",
    "**Use OpenAI When:**\n",
    "- ‚úÖ You need reliable function calling out-of-the-box\n",
    "- ‚úÖ Speed and latency are critical\n",
    "- ‚úÖ You want minimal implementation complexity\n",
    "- ‚úÖ Production reliability is paramount\n",
    "\n",
    "---\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "This pattern is used in:\n",
    "- **LangChain**: Open-source framework for LLM applications\n",
    "- **AutoGPT**: Autonomous AI agents\n",
    "- **Custom AI Assistants**: When you need full control\n",
    "- **Research Projects**: Understanding AI behavior\n",
    "\n",
    "Now let's implement it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from huggingface_hub import InferenceClient\n",
    "    \n",
    "    # Initialize HuggingFace client\n",
    "    hf_client = InferenceClient(token=HF_TOKEN)\n",
    "    \n",
    "    def create_structured_prompt(user_query: str, tools: List[Dict]) -> str:\n",
    "        \"\"\"Create a structured prompt for HuggingFace models.\"\"\"\n",
    "        tool_descriptions = []\n",
    "        for tool in tools:\n",
    "            func = tool['function']\n",
    "            tool_descriptions.append(f\"\"\"\n",
    "Tool: {func['name']}\n",
    "Description: {func['description']}\n",
    "Parameters: {json.dumps(func['parameters'], indent=2)}\n",
    "            \"\"\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are a helpful assistant with access to the following tools:\n",
    "\n",
    "{chr(10).join(tool_descriptions)}\n",
    "\n",
    "User Query: {user_query}\n",
    "\n",
    "If you need to use a tool, respond with exactly this format:\n",
    "TOOL_CALL: {{\"name\": \"tool_name\", \"arguments\": {{\"param1\": \"value1\"}}}}\n",
    "\n",
    "If no tool is needed, respond naturally.\n",
    "        \"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def parse_tool_call(response_text: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Parse tool call from model response.\"\"\"\n",
    "        if \"TOOL_CALL:\" in response_text:\n",
    "            try:\n",
    "                # Extract JSON after TOOL_CALL:\n",
    "                json_start = response_text.find(\"TOOL_CALL:\") + len(\"TOOL_CALL:\")\n",
    "                json_str = response_text[json_start:].strip()\n",
    "                return json.loads(json_str)\n",
    "            except json.JSONDecodeError:\n",
    "                return None\n",
    "        return None\n",
    "    \n",
    "    def handle_hf_function_call(user_query: str, tools: List[Dict], available_functions: Dict) -> str:\n",
    "        \"\"\"Handle function calling with HuggingFace models.\"\"\"\n",
    "        prompt = create_structured_prompt(user_query, tools)\n",
    "        \n",
    "        # Use a conversational model\n",
    "        response = hf_client.text_generation(\n",
    "            prompt,\n",
    "            model=\"microsoft/DialoGPT-medium\",\n",
    "            max_new_tokens=150,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        print(f\"Model response: {response}\")\n",
    "        \n",
    "        # Check for tool call\n",
    "        tool_call = parse_tool_call(response)\n",
    "        if tool_call:\n",
    "            function_name = tool_call['name']\n",
    "            function_args = tool_call['arguments']\n",
    "            \n",
    "            print(f\"Calling function: {function_name}\")\n",
    "            print(f\"Arguments: {function_args}\")\n",
    "            \n",
    "            # Call the actual function\n",
    "            if function_name in available_functions:\n",
    "                function_response = available_functions[function_name](**function_args)\n",
    "                \n",
    "                # Create follow-up prompt with function result\n",
    "                follow_up_prompt = f\"\"\"\n",
    "                User Query: {user_query}\n",
    "                Function Result: {json.dumps(function_response)}\n",
    "                \n",
    "                Provide a natural response to the user based on the function result.\n",
    "                \"\"\"\n",
    "                \n",
    "                final_response = hf_client.text_generation(\n",
    "                    follow_up_prompt,\n",
    "                    model=\"microsoft/DialoGPT-medium\",\n",
    "                    max_new_tokens=150,\n",
    "                    temperature=0.1\n",
    "                )\n",
    "                \n",
    "                return final_response\n",
    "            else:\n",
    "                return f\"Error: Unknown function {function_name}\"\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    # Test with HuggingFace\n",
    "    available_functions = {\n",
    "        \"make_coffee\": make_coffee,\n",
    "        \"random_coffee_fact\": random_coffee_fact\n",
    "    }\n",
    "    \n",
    "    result = handle_hf_function_call(\n",
    "        \"I'd like to make a latte. Can you give me the recipe?\",\n",
    "        coffee_tools,\n",
    "        available_functions\n",
    "    )\n",
    "    \n",
    "    print(\"\\nHuggingFace result:\")\n",
    "    print(result)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"HuggingFace Hub library not installed. Skipping this exercise.\")\n",
    "except Exception as e:\n",
    "    print(f\"HuggingFace API error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Structured Output Validation\n",
    "\n",
    "### Why Validation Is Critical\n",
    "\n",
    "**The Hard Truth:** AI models can produce invalid output. Always.\n",
    "\n",
    "**What can go wrong:**\n",
    "```json\n",
    "{\n",
    "  \"character\": {\n",
    "    \"name\": \"X\",              ‚Üê Too short!\n",
    "    \"class\": \"ninja\",         ‚Üê Not in enum!\n",
    "    \"health\": 150,            ‚Üê Exceeds maximum!\n",
    "    \"mana\": \"high\"            ‚Üê Wrong type!\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Without validation:** Your app crashes, users see errors, data gets corrupted\n",
    "\n",
    "**With validation:** You catch errors, retry, provide fallbacks, stay reliable\n",
    "\n",
    "---\n",
    "\n",
    "### The Validation Strategy\n",
    "\n",
    "**Three Layers of Defense:**\n",
    "\n",
    "1. **Schema Definition**\n",
    "   - Define what valid data looks like\n",
    "   - Use JSON Schema standard\n",
    "   - Make it strict (additionalProperties: false)\n",
    "\n",
    "2. **Pre-Execution Validation**\n",
    "   - Validate before calling functions\n",
    "   - Reject invalid data early\n",
    "   - Save computation and API calls\n",
    "\n",
    "3. **Post-Response Validation**\n",
    "   - Validate AI output before using it\n",
    "   - Retry if invalid\n",
    "   - Log failures for debugging\n",
    "\n",
    "---\n",
    "\n",
    "### JSON Schema Power\n",
    "\n",
    "**Example Constraints:**\n",
    "```json\n",
    "{\n",
    "  \"name\": {\"minLength\": 2, \"maxLength\": 20},     ‚Üê Prevents empty/huge names\n",
    "  \"class\": {\"enum\": [\"warrior\", \"mage\"]},        ‚Üê Only valid classes\n",
    "  \"health\": {\"minimum\": 50, \"maximum\": 100}      ‚Üê Balanced stats\n",
    "}\n",
    "```\n",
    "\n",
    "**Real-world impact:**\n",
    "- Medical systems: Validate drug dosages\n",
    "- Financial systems: Validate transaction amounts\n",
    "- E-commerce: Validate product IDs and quantities\n",
    "- User auth: Validate email formats and passwords\n",
    "\n",
    "Let's build robust validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_json_schema(data: Dict[str, Any], schema: Dict[str, Any]) -> bool:\n",
    "    \"\"\"Validate data against JSON schema.\"\"\"\n",
    "    try:\n",
    "        validate(instance=data, schema=schema)\n",
    "        return True\n",
    "    except ValidationError as e:\n",
    "        print(f\"Validation error: {e.message}\")\n",
    "        return False\n",
    "\n",
    "def safe_json_parse(response_text: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Extract and parse JSON from potentially mixed responses.\"\"\"\n",
    "    import re\n",
    "    \n",
    "    try:\n",
    "        # Try direct parsing first\n",
    "        return json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        # Extract JSON from code blocks\n",
    "        json_match = re.search(r'```json\\n(.*?)\\n```', response_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            return json.loads(json_match.group(1))\n",
    "        # Try to find JSON-like content\n",
    "        json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            return json.loads(json_match.group(0))\n",
    "        return None\n",
    "\n",
    "# Define a schema for game character generation\n",
    "game_character_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"character\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\"type\": \"string\", \"minLength\": 2, \"maxLength\": 20},\n",
    "                \"class\": {\"type\": \"string\", \"enum\": [\"warrior\", \"mage\", \"rogue\", \"cleric\"]},\n",
    "                \"health\": {\"type\": \"integer\", \"minimum\": 50, \"maximum\": 100},\n",
    "                \"mana\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 100},\n",
    "                \"strength\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 20},\n",
    "                \"intelligence\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 20}\n",
    "            },\n",
    "            \"required\": [\"name\", \"class\", \"health\"],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"backstory\": {\n",
    "            \"type\": \"string\",\n",
    "            \"minLength\": 50,\n",
    "            \"maxLength\": 500\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"character\", \"backstory\"],\n",
    "    \"additionalProperties\": False\n",
    "}\n",
    "\n",
    "print(\"Schema validation functions created!\")\n",
    "print(f\"Game character schema requires: {game_character_schema['required']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Provider Comparison Framework\n",
    "\n",
    "### Why Compare Providers? The Business Case\n",
    "\n",
    "**The Reality:**\n",
    "- Different providers have different strengths\n",
    "- Costs vary dramatically (10x-100x differences)\n",
    "- Latency can range from 100ms to 10+ seconds\n",
    "- Reliability varies (some have 99.9% uptime, others 95%)\n",
    "- Quality differs based on use case\n",
    "\n",
    "**Why This Matters:**\n",
    "- **Cost Optimization**: Save thousands per month by choosing the right provider\n",
    "- **Performance**: Users notice 500ms vs 5s latency\n",
    "- **Reliability**: Downtime costs money and reputation\n",
    "- **Quality**: Wrong provider = wrong answers = unhappy users\n",
    "\n",
    "---\n",
    "\n",
    "### What We're Measuring\n",
    "\n",
    "**1. JSON Validity Rate**\n",
    "- **What**: Percentage of responses that are valid JSON\n",
    "- **Why**: Invalid JSON = parsing errors = broken functionality\n",
    "- **Target**: >95% for production use\n",
    "\n",
    "**2. Schema Compliance Rate**\n",
    "- **What**: Percentage of valid JSON that matches our schema\n",
    "- **Why**: Wrong structure = wrong data = application bugs\n",
    "- **Target**: >90% for production use\n",
    "\n",
    "**3. Latency (Response Time)**\n",
    "- **What**: Time from request to response\n",
    "- **Why**: Users abandon slow applications\n",
    "- **Target**: <2s for most use cases, <500ms for real-time\n",
    "\n",
    "**4. Error Rate**\n",
    "- **What**: Percentage of requests that fail\n",
    "- **Why**: Errors = unhappy users = lost revenue\n",
    "- **Target**: <1% for production use\n",
    "\n",
    "**5. Cost per Request**\n",
    "- **What**: Total cost divided by number of requests\n",
    "- **Why**: Scale matters‚Äîsmall differences add up\n",
    "- **Target**: Balance with quality requirements\n",
    "\n",
    "---\n",
    "\n",
    "### The Evaluation Framework Architecture\n",
    "\n",
    "**Design Principles:**\n",
    "\n",
    "1. **Systematic Testing**: Same prompts across all providers\n",
    "2. **Multiple Metrics**: Don't optimize for just one thing\n",
    "3. **Statistical Significance**: Test enough to be confident\n",
    "4. **Real-World Scenarios**: Use actual use case prompts\n",
    "5. **Reproducible**: Same inputs = same results\n",
    "\n",
    "**The Flow:**\n",
    "\n",
    "```\n",
    "For each provider:\n",
    "    For each test prompt:\n",
    "        1. Send request with timing\n",
    "        2. Parse response\n",
    "        3. Validate JSON structure\n",
    "        4. Validate against schema\n",
    "        5. Record metrics\n",
    "    6. Calculate statistics\n",
    "7. Compare across providers\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Understanding the Metrics\n",
    "\n",
    "**Valid JSON Count:**\n",
    "```python\n",
    "try:\n",
    "    parsed = json.loads(response_text)\n",
    "    valid_json_count += 1\n",
    "except json.JSONDecodeError:\n",
    "    # Invalid JSON - can't use this response\n",
    "    pass\n",
    "```\n",
    "**Why it matters**: If JSON is invalid, you can't extract data. This is a hard requirement.\n",
    "\n",
    "**Schema Compliance:**\n",
    "```python\n",
    "if validate_json_schema(parsed_data, schema):\n",
    "    schema_compliant_count += 1\n",
    "```\n",
    "**Why it matters**: Even valid JSON might have wrong structure. Schema validation catches:\n",
    "- Missing required fields\n",
    "- Wrong data types\n",
    "- Values outside allowed ranges\n",
    "- Extra unexpected fields\n",
    "\n",
    "**Latency Tracking:**\n",
    "```python\n",
    "start_time = time.time()\n",
    "response = client.generate(...)\n",
    "latency = time.time() - start_time\n",
    "```\n",
    "**Why it matters**: \n",
    "- **P50 (Median)**: Typical user experience\n",
    "- **P95**: Worst-case for most users (5% are slower)\n",
    "- **P99**: Extreme cases (1% are slower)\n",
    "\n",
    "**Error Handling:**\n",
    "```python\n",
    "try:\n",
    "    response = client.generate(...)\n",
    "except Exception as e:\n",
    "    errors.append(str(e))\n",
    "```\n",
    "**Why it matters**: Different providers fail in different ways:\n",
    "- Network timeouts\n",
    "- Rate limiting\n",
    "- Invalid API keys\n",
    "- Model unavailable\n",
    "\n",
    "---\n",
    "\n",
    "### Interpreting Results\n",
    "\n",
    "**Example Results:**\n",
    "```\n",
    "Provider A: 98% valid JSON, 1.2s avg latency, $0.01/request\n",
    "Provider B: 95% valid JSON, 0.5s avg latency, $0.05/request\n",
    "Provider C: 99% valid JSON, 3.0s avg latency, $0.001/request\n",
    "```\n",
    "\n",
    "**Decision Framework:**\n",
    "- **High volume, cost-sensitive**: Choose Provider C\n",
    "- **Real-time, quality-critical**: Choose Provider B\n",
    "- **Balanced requirements**: Choose Provider A\n",
    "\n",
    "**Trade-offs:**\n",
    "- **Speed vs Cost**: Faster usually costs more\n",
    "- **Quality vs Speed**: Better models often slower\n",
    "- **Reliability vs Cost**: More reliable = more expensive\n",
    "\n",
    "---\n",
    "\n",
    "### Production Best Practices\n",
    "\n",
    "**1. Continuous Monitoring**\n",
    "- Don't just test once‚Äîmonitor ongoing performance\n",
    "- Providers change over time\n",
    "- Your use case might evolve\n",
    "\n",
    "**2. A/B Testing**\n",
    "- Test new providers alongside existing ones\n",
    "- Gradually shift traffic based on results\n",
    "- Keep fallback options\n",
    "\n",
    "**3. Multi-Provider Strategy**\n",
    "- Use primary + backup providers\n",
    "- Route based on request type\n",
    "- Failover automatically\n",
    "\n",
    "**4. Cost Tracking**\n",
    "- Monitor actual spending, not just per-request costs\n",
    "- Include infrastructure costs (if self-hosting)\n",
    "- Factor in developer time for maintenance\n",
    "\n",
    "Now let's build the framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_provider_performance(client, test_prompts: List[str], schema: Dict[str, Any], provider_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"Evaluate provider performance across multiple metrics.\"\"\"\n",
    "    results = {\n",
    "        'provider': provider_name,\n",
    "        'total_tests': len(test_prompts),\n",
    "        'valid_json_count': 0,\n",
    "        'schema_compliant_count': 0,\n",
    "        'total_latency': 0,\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    for i, prompt in enumerate(test_prompts):\n",
    "        print(f\"Testing prompt {i+1}/{len(test_prompts)}: {prompt[:50]}...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            # This is a simplified version - adapt based on your client type\n",
    "            if hasattr(client, 'chat_completions'):\n",
    "                # OpenAI-style client\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[{\"role\": \"user\", \"content\": f\"Generate a game character. {prompt}\"}],\n",
    "                    response_format={\"type\": \"json_object\"}\n",
    "                )\n",
    "                response_text = response.choices[0].message.content\n",
    "            else:\n",
    "                # HuggingFace-style client\n",
    "                structured_prompt = f\"\"\"\n",
    "                Generate a game character based on this request: {prompt}\n",
    "                \n",
    "                Respond with valid JSON that matches this schema:\n",
    "                {json.dumps(game_character_schema, indent=2)}\n",
    "                \n",
    "                Output only the JSON, no additional text.\n",
    "                \"\"\"\n",
    "                response_text = client.text_generation(structured_prompt, max_new_tokens=500)\n",
    "            \n",
    "            latency = time.time() - start_time\n",
    "            results['total_latency'] += latency\n",
    "            \n",
    "            # Parse and validate response\n",
    "            parsed_data = safe_json_parse(response_text)\n",
    "            if parsed_data:\n",
    "                results['valid_json_count'] += 1\n",
    "                if validate_json_schema(parsed_data, schema):\n",
    "                    results['schema_compliant_count'] += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            results['errors'].append(str(e))\n",
    "            print(f\"Error: {e}\")\n",
    "    \n",
    "    # Calculate averages and percentages\n",
    "    if results['total_tests'] > 0:\n",
    "        results['valid_json_rate'] = (results['valid_json_count'] / results['total_tests']) * 100\n",
    "        results['schema_compliance_rate'] = (results['schema_compliant_count'] / results['total_tests']) * 100\n",
    "        results['avg_latency'] = results['total_latency'] / results['total_tests']\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test prompts for evaluation\n",
    "test_prompts = [\n",
    "    \"Create a brave warrior with high health and strength.\",\n",
    "    \"Generate an intelligent mage with powerful magic abilities.\",\n",
    "    \"Create a stealthy rogue character.\",\n",
    "    \"Make a wise cleric with healing powers.\",\n",
    "    \"Generate a balanced character with moderate stats.\"\n",
    "]\n",
    "\n",
    "print(\"Provider comparison framework created!\")\n",
    "print(f\"Test prompts prepared: {len(test_prompts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Local Model Integration with Ollama\n",
    "\n",
    "### Why Run Models Locally? The Privacy and Cost Advantage\n",
    "\n",
    "**The Local Model Revolution:**\n",
    "\n",
    "Running AI models on your own machine gives you:\n",
    "- **Zero API Costs**: No per-request charges\n",
    "- **Complete Privacy**: Data never leaves your machine\n",
    "- **No Rate Limits**: Use as much as you want\n",
    "- **Offline Capability**: Works without internet\n",
    "- **Full Control**: Customize models, fine-tune, modify\n",
    "\n",
    "**When Local Makes Sense:**\n",
    "- Processing sensitive data (medical, financial, legal)\n",
    "- High-volume use cases (cost savings)\n",
    "- Development and testing (faster iteration)\n",
    "- Compliance requirements (data residency)\n",
    "- Learning and experimentation\n",
    "\n",
    "---\n",
    "\n",
    "### Understanding Ollama\n",
    "\n",
    "**What is Ollama?**\n",
    "- **Local LLM Runtime**: Runs large language models on your machine\n",
    "- **Open Source**: Free and community-driven\n",
    "- **Easy Setup**: Simple installation and model management\n",
    "- **OpenAI-Compatible API**: Can use same code patterns\n",
    "- **Model Library**: Access to Llama, Mistral, CodeLlama, and more\n",
    "\n",
    "**How It Works:**\n",
    "1. **Download Models**: `ollama pull llama2` downloads model weights\n",
    "2. **Start Server**: `ollama serve` runs local API server\n",
    "3. **Make Requests**: Use HTTP API like OpenAI\n",
    "4. **Models Run Locally**: All computation happens on your machine\n",
    "\n",
    "**System Requirements:**\n",
    "- **RAM**: 8GB+ for smaller models, 16GB+ for larger ones\n",
    "- **Storage**: 4-20GB per model (depending on size)\n",
    "- **CPU/GPU**: Works on CPU but much faster with GPU\n",
    "\n",
    "---\n",
    "\n",
    "### The Integration Pattern\n",
    "\n",
    "**Step 1: Check if Ollama is Running**\n",
    "```python\n",
    "response = requests.get(\"http://localhost:11434/api/tags\")\n",
    "if response.status_code == 200:\n",
    "    # Ollama is running!\n",
    "```\n",
    "**Why**: Ollama runs as a local server. We need to verify it's available before using it.\n",
    "\n",
    "**Step 2: List Available Models**\n",
    "```python\n",
    "models = response.json().get('models', [])\n",
    "model_names = [model['name'] for model in models]\n",
    "```\n",
    "**Why**: Different models have different capabilities. We want to use the best available one.\n",
    "\n",
    "**Step 3: Make API Request**\n",
    "```python\n",
    "payload = {\n",
    "    \"model\": \"llama2\",\n",
    "    \"prompt\": \"Your prompt here\",\n",
    "    \"format\": \"json\",  # Request structured output\n",
    "    \"stream\": False    # Get complete response\n",
    "}\n",
    "response = requests.post(\"http://localhost:11434/api/generate\", json=payload)\n",
    "```\n",
    "**Why**: Ollama uses HTTP REST API, similar to OpenAI but simpler.\n",
    "\n",
    "**Step 4: Parse Response**\n",
    "```python\n",
    "result = response.json()\n",
    "generated_text = result.get('response', '')\n",
    "```\n",
    "**Why**: Ollama returns JSON with the generated text in the `response` field.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Differences from Cloud APIs\n",
    "\n",
    "| Aspect | OpenAI/HuggingFace | Ollama |\n",
    "|--------|-------------------|--------|\n",
    "| **Location** | Remote servers | Your machine |\n",
    "| **Cost** | Per-request pricing | Free (hardware cost) |\n",
    "| **Speed** | Fast (powerful GPUs) | Depends on your hardware |\n",
    "| **Privacy** | Data sent to provider | Data stays local |\n",
    "| **Setup** | API key only | Install + download models |\n",
    "| **Scalability** | Handled by provider | Limited by your hardware |\n",
    "\n",
    "---\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "**Advantages:**\n",
    "- ‚úÖ No ongoing API costs\n",
    "- ‚úÖ Complete data privacy\n",
    "- ‚úÖ No rate limits\n",
    "- ‚úÖ Works offline\n",
    "\n",
    "**Challenges:**\n",
    "- ‚ö†Ô∏è Requires powerful hardware\n",
    "- ‚ö†Ô∏è Setup and maintenance overhead\n",
    "- ‚ö†Ô∏è Limited scalability (single machine)\n",
    "- ‚ö†Ô∏è Model updates require manual downloads\n",
    "\n",
    "**Hybrid Approach:**\n",
    "Many production systems use both:\n",
    "- **Local models** for sensitive/private data\n",
    "- **Cloud APIs** for public-facing features\n",
    "- **Automatic failover** from cloud to local if needed\n",
    "\n",
    "---\n",
    "\n",
    "### Real-World Use Cases\n",
    "\n",
    "**1. Development and Testing**\n",
    "- Test function calling without API costs\n",
    "- Iterate quickly on prompts\n",
    "- Debug issues locally\n",
    "\n",
    "**2. Sensitive Data Processing**\n",
    "- Medical records analysis\n",
    "- Financial document processing\n",
    "- Legal document review\n",
    "\n",
    "**3. High-Volume Applications**\n",
    "- Content generation at scale\n",
    "- Data extraction from documents\n",
    "- Batch processing jobs\n",
    "\n",
    "**4. Compliance Requirements**\n",
    "- GDPR (data must stay in EU)\n",
    "- HIPAA (healthcare data privacy)\n",
    "- Financial regulations\n",
    "\n",
    "Now let's test the integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ollama_integration():\n",
    "    \"\"\"Test integration with local Ollama instance.\"\"\"\n",
    "    try:\n",
    "        # Check if Ollama is running\n",
    "        ollama_response = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "        if ollama_response.status_code == 200:\n",
    "            print(\"Ollama is running!\")\n",
    "            models = ollama_response.json().get('models', [])\n",
    "            print(f\"Available models: {[model['name'] for model in models]}\")\n",
    "            \n",
    "            # Test with a simple prompt\n",
    "            test_payload = {\n",
    "                \"model\": \"llama2\" if any('llama2' in m['name'] for m in models) else models[0]['name'],\n",
    "                \"prompt\": \"Generate a simple JSON object with 'name' and 'age' fields.\",\n",
    "                \"format\": \"json\",\n",
    "                \"stream\": False\n",
    "            }\n",
    "            \n",
    "            response = requests.post(\n",
    "                \"http://localhost:11434/api/generate\",\n",
    "                json=test_payload,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                print(f\"Ollama response: {result.get('response', 'No response')}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"Ollama API error: {response.status_code}\")\n",
    "                return False\n",
    "        else:\n",
    "            print(\"Ollama is not responding properly\")\n",
    "            return False\n",
    "            \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Ollama is not running. Start it with: ollama serve\")\n",
    "        return False\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"Ollama connection timed out\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Ollama: {e}\")\n",
    "        return False\n",
    "\n",
    "# Test Ollama integration\n",
    "print(\"Testing Ollama integration...\")\n",
    "ollama_available = test_ollama_integration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Final Project - Game Character Generator\n",
    "\n",
    "### Building Production-Ready AI Applications\n",
    "\n",
    "**What Makes This \"Production-Ready\"?**\n",
    "\n",
    "This exercise combines everything you've learned into a **real-world application**:\n",
    "\n",
    "1. **Multi-Provider Support**: Works with OpenAI, HuggingFace, and Ollama\n",
    "2. **Robust Validation**: Schema validation with retry logic\n",
    "3. **Error Handling**: Graceful failures with informative messages\n",
    "4. **Retry Logic**: Automatically retry on failures\n",
    "5. **Structured Output**: Guaranteed valid data structure\n",
    "\n",
    "---\n",
    "\n",
    "### The Architecture: Class-Based Design\n",
    "\n",
    "**Why Use a Class?**\n",
    "\n",
    "```python\n",
    "class GameCharacterGenerator:\n",
    "    def __init__(self, provider, api_key):\n",
    "        # Initialize once, use many times\n",
    "        self.provider = provider\n",
    "        self.client = self._initialize_client()\n",
    "    \n",
    "    def generate_character(self, user_request):\n",
    "        # Clean interface for generation\n",
    "        # Handles all complexity internally\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- **Encapsulation**: All provider logic in one place\n",
    "- **Reusability**: Create multiple generators easily\n",
    "- **Testability**: Easy to mock and test\n",
    "- **Maintainability**: Changes isolated to class\n",
    "\n",
    "---\n",
    "\n",
    "### The Retry Pattern: Why It Matters\n",
    "\n",
    "**The Problem:**\n",
    "AI models are **probabilistic**, not deterministic:\n",
    "- Same input ‚Üí different outputs\n",
    "- Sometimes outputs are invalid\n",
    "- Network issues cause failures\n",
    "- Rate limits cause temporary errors\n",
    "\n",
    "**The Solution: Retry with Validation**\n",
    "\n",
    "```python\n",
    "max_attempts = 3\n",
    "for attempt in range(max_attempts):\n",
    "    try:\n",
    "        response = self._generate(...)\n",
    "        if validate_json_schema(response, schema):\n",
    "            return response  # Success!\n",
    "    except Exception as e:\n",
    "        if attempt == max_attempts - 1:\n",
    "            return error  # Give up after max attempts\n",
    "        # Otherwise, retry\n",
    "```\n",
    "\n",
    "**Why This Works:**\n",
    "- **First attempt**: Usually succeeds (fast path)\n",
    "- **Second attempt**: Catches occasional failures\n",
    "- **Third attempt**: Handles persistent issues\n",
    "- **After 3 attempts**: Return error (don't loop forever)\n",
    "\n",
    "**Real-World Impact:**\n",
    "- Without retry: 5-10% failure rate\n",
    "- With retry: <1% failure rate\n",
    "- **10x improvement in reliability**\n",
    "\n",
    "---\n",
    "\n",
    "### Provider Abstraction: The Power of Interfaces\n",
    "\n",
    "**The Challenge:**\n",
    "Each provider has different APIs:\n",
    "- OpenAI: `client.chat.completions.create(...)`\n",
    "- HuggingFace: `client.text_generation(...)`\n",
    "- Ollama: `requests.post(\"http://localhost:11434/api/generate\", ...)`\n",
    "\n",
    "**The Solution: Provider-Specific Methods**\n",
    "\n",
    "```python\n",
    "def generate_character(self, user_request):\n",
    "    if self.provider == \"openai\":\n",
    "        return self._generate_openai_character(user_request)\n",
    "    elif self.provider == \"huggingface\":\n",
    "        return self._generate_hf_character(user_request)\n",
    "    elif self.provider == \"ollama\":\n",
    "        return self._generate_ollama_character(user_request)\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- **Single Interface**: `generate_character()` works for all\n",
    "- **Easy to Extend**: Add new providers without changing calling code\n",
    "- **Provider-Specific Optimization**: Each method optimized for its provider\n",
    "- **Testing**: Test each provider independently\n",
    "\n",
    "---\n",
    "\n",
    "### Validation Strategy: Defense in Depth\n",
    "\n",
    "**Layer 1: Schema Definition**\n",
    "```python\n",
    "schema = {\n",
    "    \"name\": {\"minLength\": 2, \"maxLength\": 20},\n",
    "    \"class\": {\"enum\": [\"warrior\", \"mage\", \"rogue\", \"cleric\"]},\n",
    "    \"health\": {\"minimum\": 50, \"maximum\": 100}\n",
    "}\n",
    "```\n",
    "**Purpose**: Define what \"valid\" means\n",
    "\n",
    "**Layer 2: Pre-Execution Validation**\n",
    "```python\n",
    "# Validate before sending to AI\n",
    "if not is_valid_request(user_request):\n",
    "    return error\n",
    "```\n",
    "**Purpose**: Catch obvious errors early\n",
    "\n",
    "**Layer 3: Post-Response Validation**\n",
    "```python\n",
    "if validate_json_schema(response, schema):\n",
    "    return response\n",
    "else:\n",
    "    # Retry or return error\n",
    "```\n",
    "**Purpose**: Ensure AI output meets requirements\n",
    "\n",
    "**Layer 4: Runtime Validation**\n",
    "```python\n",
    "# Validate when using the data\n",
    "if character['health'] > 100:\n",
    "    raise ValueError(\"Invalid health value\")\n",
    "```\n",
    "**Purpose**: Final safety check before using data\n",
    "\n",
    "---\n",
    "\n",
    "### Error Handling: User-Friendly Messages\n",
    "\n",
    "**Bad Error Handling:**\n",
    "```python\n",
    "except Exception as e:\n",
    "    return {\"error\": str(e)}\n",
    "# User sees: \"KeyError: 'name'\"\n",
    "```\n",
    "\n",
    "**Good Error Handling:**\n",
    "```python\n",
    "except Exception as e:\n",
    "    return {\n",
    "        \"success\": False,\n",
    "        \"error\": \"Failed to generate valid character after maximum attempts\",\n",
    "        \"attempts\": max_attempts,\n",
    "        \"details\": str(e)  # For debugging\n",
    "    }\n",
    "# User sees: Clear message, developer sees: Technical details\n",
    "```\n",
    "\n",
    "**Why It Matters:**\n",
    "- **Users**: Need to understand what went wrong\n",
    "- **Developers**: Need technical details to fix issues\n",
    "- **Monitoring**: Need structured data for alerting\n",
    "\n",
    "---\n",
    "\n",
    "### Production Deployment Checklist\n",
    "\n",
    "Before deploying this to production:\n",
    "\n",
    "- [ ] **Environment Variables**: API keys in `.env`, not code\n",
    "- [ ] **Logging**: Log all requests and responses\n",
    "- [ ] **Monitoring**: Track success rates, latency, errors\n",
    "- [ ] **Rate Limiting**: Prevent abuse\n",
    "- [ ] **Caching**: Cache common requests\n",
    "- [ ] **Documentation**: API docs for other developers\n",
    "- [ ] **Testing**: Unit tests for each provider\n",
    "- [ ] **Error Recovery**: Graceful degradation on failures\n",
    "\n",
    "---\n",
    "\n",
    "### What You've Built\n",
    "\n",
    "This generator demonstrates:\n",
    "- ‚úÖ **Multi-provider architecture** (OpenAI, HuggingFace, Ollama)\n",
    "- ‚úÖ **Robust validation** (schema validation with retries)\n",
    "- ‚úÖ **Error handling** (graceful failures)\n",
    "- ‚úÖ **Production patterns** (class-based, testable, maintainable)\n",
    "- ‚úÖ **Real-world complexity** (handles edge cases)\n",
    "\n",
    "**Next Steps:**\n",
    "- Add more providers (Anthropic, Cohere, etc.)\n",
    "- Implement caching for common requests\n",
    "- Add streaming responses for better UX\n",
    "- Build a web API wrapper\n",
    "- Add monitoring and analytics\n",
    "\n",
    "Now let's build it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameCharacterGenerator:\n",
    "    \"\"\"A robust game character generator with multiple provider support.\"\"\"\n",
    "    \n",
    "    def __init__(self, provider: str = \"openai\", api_key: str = None):\n",
    "        self.provider = provider\n",
    "        self.api_key = api_key\n",
    "        self.client = self._initialize_client()\n",
    "    \n",
    "    def _initialize_client(self):\n",
    "        \"\"\"Initialize the appropriate client based on provider.\"\"\"\n",
    "        if self.provider == \"openai\":\n",
    "            try:\n",
    "                from openai import OpenAI\n",
    "                return OpenAI(api_key=self.api_key)\n",
    "            except ImportError:\n",
    "                raise ImportError(\"OpenAI library not installed\")\n",
    "        elif self.provider == \"huggingface\":\n",
    "            try:\n",
    "                from huggingface_hub import InferenceClient\n",
    "                return InferenceClient(token=self.api_key)\n",
    "            except ImportError:\n",
    "                raise ImportError(\"HuggingFace Hub library not installed\")\n",
    "        elif self.provider == \"ollama\":\n",
    "            return None  # Ollama uses HTTP requests\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown provider: {self.provider}\")\n",
    "    \n",
    "    def generate_character(self, user_request: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate a game character with validation.\"\"\"\n",
    "        max_attempts = 3\n",
    "        \n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                if self.provider == \"openai\":\n",
    "                    response = self._generate_openai_character(user_request)\n",
    "                elif self.provider == \"huggingface\":\n",
    "                    response = self._generate_hf_character(user_request)\n",
    "                elif self.provider == \"ollama\":\n",
    "                    response = self._generate_ollama_character(user_request)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown provider: {self.provider}\")\n",
    "                \n",
    "                # Validate the response\n",
    "                if validate_json_schema(response, game_character_schema):\n",
    "                    return {\n",
    "                        \"success\": True,\n",
    "                        \"character\": response,\n",
    "                        \"attempts\": attempt + 1\n",
    "                    }\n",
    "                else:\n",
    "                    print(f\"Attempt {attempt + 1}: Schema validation failed\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Attempt {attempt + 1}: Error - {e}\")\n",
    "        \n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": \"Failed to generate valid character after maximum attempts\",\n",
    "            \"attempts\": max_attempts\n",
    "        }\n",
    "    \n",
    "    def _generate_openai_character(self, user_request: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate character using OpenAI.\"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"Generate a game character based on the user's request. Respond with valid JSON that matches this schema: {json.dumps(game_character_schema)}\"\n",
    "            }, {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_request\n",
    "            }],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        response_text = response.choices[0].message.content\n",
    "        return safe_json_parse(response_text)\n",
    "    \n",
    "    def _generate_hf_character(self, user_request: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate character using HuggingFace.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Generate a game character based on this request: {user_request}\n",
    "        \n",
    "        Respond with valid JSON that matches this schema:\n",
    "        {json.dumps(game_character_schema, indent=2)}\n",
    "        \n",
    "        Output only the JSON, no additional text.\n",
    "        \"\"\"\n",
    "        \n",
    "        response_text = self.client.text_generation(prompt, max_new_tokens=500)\n",
    "        return safe_json_parse(response_text)\n",
    "    \n",
    "    def _generate_ollama_character(self, user_request: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate character using Ollama.\"\"\"\n",
    "        payload = {\n",
    "            \"model\": \"llama2\",\n",
    "            \"prompt\": f\"Generate a game character based on this request: {user_request}\",\n",
    "            \"format\": \"json\",\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        response = requests.post(\"http://localhost:11434/api/generate\", json=payload)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return safe_json_parse(result.get('response', '{}'))\n",
    "        else:\n",
    "            raise Exception(f\"Ollama API error: {response.status_code}\")\n",
    "\n",
    "# Test the character generator\n",
    "print(\"Testing Game Character Generator...\")\n",
    "\n",
    "# Test with different providers\n",
    "providers_to_test = []\n",
    "if OPENAI_API_KEY != \"your-openai-key-here\":\n",
    "    providers_to_test.append(\"openai\")\n",
    "if HF_TOKEN != \"your-huggingface-token-here\":\n",
    "    providers_to_test.append(\"huggingface\")\n",
    "if ollama_available:\n",
    "    providers_to_test.append(\"ollama\")\n",
    "\n",
    "for provider in providers_to_test:\n",
    "    try:\n",
    "        print(f\"\\n--- Testing {provider.upper()} ---\")\n",
    "        generator = GameCharacterGenerator(provider=provider, api_key=OPENAI_API_KEY if provider == \"openai\" else HF_TOKEN)\n",
    "        result = generator.generate_character(\"Create a brave warrior with high strength and good health.\")\n",
    "        \n",
    "        if result['success']:\n",
    "            print(f\"‚úÖ Character generated successfully in {result['attempts']} attempt(s)\")\n",
    "            character = result['character']['character']\n",
    "            print(f\"Name: {character['name']}\")\n",
    "            print(f\"Class: {character['class']}\")\n",
    "            print(f\"Health: {character['health']}\")\n",
    "            print(f\"Strength: {character['strength']}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to generate character: {result['error']}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing {provider}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "Congratulations! You've completed the Function Calling and Structured Outputs lab. Here's what you've learned:\n",
    "\n",
    "### Key Skills Acquired:\n",
    "- ‚úÖ Function calling implementation with JSON Schema\n",
    "- ‚úÖ Cross-platform AI provider integration (OpenAI, HuggingFace, Ollama)\n",
    "- ‚úÖ Structured output validation and error handling\n",
    "- ‚úÖ Provider performance comparison and evaluation\n",
    "- ‚úÖ Building robust AI applications with retry logic\n",
    "\n",
    "### Best Practices:\n",
    "- Always validate AI outputs against schemas\n",
    "- Implement proper error handling and retry mechanisms\n",
    "- Use environment variables for API keys\n",
    "- Test across multiple providers for reliability\n",
    "- Handle JSON parsing edge cases gracefully\n",
    "\n",
    "### Next Steps:\n",
    "1. Experiment with different schemas for your use cases\n",
    "2. Try integrating with other AI providers\n",
    "3. Build more complex function calling scenarios\n",
    "4. Implement caching for better performance\n",
    "5. Add monitoring and logging for production use\n",
    "\n",
    "### Additional Resources:\n",
    "- [JSON Schema Documentation](https://json-schema.org/)\n",
    "- [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)\n",
    "- [HuggingFace Inference API](https://huggingface.co/docs/api-inference/index)\n",
    "- [Ollama Documentation](https://ollama.ai/)\n",
    "\n",
    "Remember: The key to reliable AI applications is robust validation, proper error handling, and thorough testing across different scenarios and providers!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
