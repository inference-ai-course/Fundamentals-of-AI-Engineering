{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 — Part 03: Preparing for Level 2 (what changes)\n",
    "\n",
    "**Estimated time:** 30–45 minutes\n",
    "\n",
    "## What success looks like (end of Part 03)\n",
    "\n",
    "- You can describe at least 3 ways Level 2 differs from Foundations Course.\n",
    "- You can name at least 2 new failure surfaces (e.g., retrieval quality, prompt injection).\n",
    "- You write a short readiness checklist artifact under `output/`.\n",
    "\n",
    "### Checkpoint\n",
    "\n",
    "After running this notebook, you should have:\n",
    "\n",
    "- `output/LEVEL2_SELF_CHECK.md`\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Identify the shift from scripts to systems in Level 2\n",
    "- Understand new failure surfaces (retrieval, evaluation, agents)\n",
    "- Capture practical mindset shifts for Level 2 work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e336aed",
   "metadata": {},
   "source": [
    "### What this part covers\n",
    "This notebook helps you understand **what shifts when you move from Foundations Course to Level 2** — so you know what to expect and what to prepare.\n",
    "\n",
    "**Foundations Course (what you've built):**\n",
    "- Single-project pipeline scripts\n",
    "- Offline, batch processing\n",
    "- Reproducibility and reliability basics\n",
    "- One LLM call per pipeline run\n",
    "\n",
    "**Level 2 (what's coming):**\n",
    "- **RAG** (Retrieval-Augmented Generation) — retrieve relevant documents, augment the prompt with them\n",
    "- **Evaluation loops** — automated metrics to measure quality, not just manual inspection\n",
    "- **Multi-step agent workflows** — chains of LLM calls where each step depends on the previous\n",
    "- **FastAPI services** — expose your pipeline as an HTTP endpoint\n",
    "\n",
    "**Everything you learned here transfers directly:** environments, error handling, timeouts, retries, caching, artifact saving, testing — all of it applies in Level 2, just at larger scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c55b96",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Foundations Course is mostly:\n",
    "\n",
    "- a single-project pipeline\n",
    "- mostly offline, script-based\n",
    "- focusing on reproducibility and reliability basics\n",
    "\n",
    "Level 2 shifts toward **systems thinking**:\n",
    "\n",
    "- retrieval (RAG)\n",
    "- evaluation loops\n",
    "- multi-step agent workflows\n",
    "- knowledge bases\n",
    "\n",
    "---\n",
    "\n",
    "## Underlying theory: Level 2 adds feedback loops and new failure surfaces\n",
    "\n",
    "In Foundations Course, many workflows are “run once and inspect outputs”.\n",
    "\n",
    "In Level 2, you build systems with feedback loops:\n",
    "\n",
    "- retrieval quality affects generation quality\n",
    "- evaluation metrics guide iteration\n",
    "- multi-step workflows introduce compounding failure probability\n",
    "\n",
    "Practical implication:\n",
    "\n",
    "- you need observability (traces/logs) to debug why a system answered\n",
    "- you need eval sets to prevent “prompt overfitting”\n",
    "- you need trust boundaries to resist prompt injection when external data is involved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56732aa",
   "metadata": {},
   "source": [
    "### What this cell does\n",
    "Defines `level2_self_check_todo()` — a list of readiness items — and writes them to `output/LEVEL2_SELF_CHECK.md`.\n",
    "\n",
    "**Why a self-check list?** Before starting Level 2, it's useful to know which concepts you're confident about and which need more study. The items cover the key new concepts you'll encounter:\n",
    "\n",
    "- **RAG** — Retrieval-Augmented Generation: instead of sending all data to the LLM, first retrieve only the relevant parts\n",
    "- **Evaluation sets** — a fixed set of test cases with known expected outputs, used to measure quality objectively\n",
    "- **Prompt injection** — when external data in a retrieval system contains instructions that hijack the LLM's behavior\n",
    "- **Observability** — logs and traces that let you understand *why* a multi-step system produced a specific output\n",
    "\n",
    "**Your task:** Replace the `<todo: ...>` placeholders with your own honest self-assessment. Be specific — \"I can explain what RAG is\" is more useful than \"I understand AI.\" The solution in the Appendix shows example items you can adapt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064e890c",
   "metadata": {},
   "source": [
    "## Practical mindset shifts\n",
    "\n",
    "- From “one script works” → “the system is observable and testable”.\n",
    "- From “prompting” → “prompt + retrieval + evaluation”.\n",
    "- From “manual checking” → “repeatable eval sets”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a7f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def level2_self_check_todo() -> List[str]:\n",
    "    # TODO: add your own readiness checklist.\n",
    "    return [\n",
    "        \"<todo: I can explain what RAG is and why it helps>\",\n",
    "        \"<todo: I know how to build a small evaluation set>\",\n",
    "        \"<todo: I understand prompt injection risk in retrieval systems>\",\n",
    "    ]\n",
    "\n",
    "\n",
    "items = level2_self_check_todo()\n",
    "\n",
    "out_path = OUTPUT_DIR / \"LEVEL2_SELF_CHECK.md\"\n",
    "out_path.write_text(\"\\n\".join([\"# Level 2 Self-Check\", \"\"] + [\"- \" + x for x in items]) + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"Level 2 self-check:\")\n",
    "for item in items:\n",
    "    print(\"-\", item)\n",
    "print(\"wrote:\", out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1eb00e",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- RAG overview: https://www.pinecone.io/learn/retrieval-augmented-generation/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc2408",
   "metadata": {},
   "source": [
    "## Self-check\n",
    "\n",
    "- Can you explain how retrieval quality affects generation quality?\n",
    "- Do you have a plan for eval sets and metrics?\n",
    "- Do you know how to handle prompt injection risks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14abc72",
   "metadata": {},
   "source": [
    "## Appendix: Solutions (peek only after trying)\n",
    "\n",
    "Reference implementation for `level2_self_check_todo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a70456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level2_self_check_todo() -> List[str]:\n",
    "    return [\n",
    "        \"I can explain what RAG is and why it helps.\",\n",
    "        \"I can describe a minimal chunking + embedding + retrieval pipeline.\",\n",
    "        \"I know how to build a small evaluation set and choose at least one metric.\",\n",
    "        \"I understand prompt injection risk and can name at least one mitigation.\",\n",
    "        \"I know why observability (logs/traces) matters for multi-step systems.\",\n",
    "    ]\n",
    "\n",
    "\n",
    "solution_path = OUTPUT_DIR / \"LEVEL2_SELF_CHECK_solution.md\"\n",
    "items = level2_self_check_todo()\n",
    "solution_path.write_text(\"\\n\".join([\"# Level 2 Self-Check\", \"\"] + [\"- \" + x for x in items]) + \"\\n\", encoding=\"utf-8\")\n",
    "print(\"wrote:\", solution_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
