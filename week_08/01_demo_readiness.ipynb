{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 — Part 01: Demo readiness checklist + README polishing\n",
    "\n",
    "**Estimated time:** 45–75 minutes\n",
    "\n",
    "## What success looks like (end of Part 01)\n",
    "\n",
    "- You can produce a demo checklist that another person can follow.\n",
    "- You can list a “happy path” run command and expected artifacts under `output/`.\n",
    "- You can describe (and demo) at least one failure case with clear evidence.\n",
    "\n",
    "### Checkpoint\n",
    "\n",
    "After running this notebook, you should have:\n",
    "\n",
    "- an `output/DEMO_CHECKLIST.md` file\n",
    "- a checklist that includes setup, run command, expected outputs, and a failure case\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Define what makes a demo reproducible\n",
    "- Build a demo readiness checklist\n",
    "- Capture a failure-case story with evidence\n",
    "- Improve README clarity for setup + run steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d21538b",
   "metadata": {},
   "source": [
    "### What this part covers\n",
    "This notebook helps you prepare for a **reproducible demo** — one that another person can follow from scratch without asking you questions.\n",
    "\n",
    "**A demo is an argument with evidence.** You're claiming:\n",
    "- \"The system runs from scratch\" → evidence: README + one-command runner\n",
    "- \"The outputs are stable\" → evidence: `report.json` with consistent fields\n",
    "- \"Failures are explainable\" → evidence: a failure case story with logs/artifacts\n",
    "\n",
    "**The \"fresh clone\" test:** Can someone clone your repo, follow the README, and run the pipeline successfully — without you in the room? If yes, your demo is reproducible. If no, find what's missing and fix it before the demo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d4d238",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "A demo is successful when another person can reproduce it.\n",
    "\n",
    "---\n",
    "\n",
    "## Underlying theory: a demo is an argument with evidence\n",
    "\n",
    "When you demo, you are implicitly making claims:\n",
    "\n",
    "- “the system runs from scratch”\n",
    "- “the outputs are stable and interpretable”\n",
    "- “failures are explainable”\n",
    "\n",
    "The README + one-command runner are the evidence that supports those claims.\n",
    "\n",
    "Practical implication:\n",
    "\n",
    "- if your demo requires “magic steps”, it is not reproducible\n",
    "- a failure-case story increases credibility because it shows you understand system limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcfca38",
   "metadata": {},
   "source": [
    "### What this cell does\n",
    "Defines `DemoChecklist` — a typed dataclass for your demo plan — and `write_readme_checklist()` — writes it as a Markdown file to `output/DEMO_CHECKLIST.md`.\n",
    "\n",
    "**Why write the checklist to a file?** A checklist in a file is an artifact — you can commit it, share it, and follow it during the actual demo without relying on memory. It also forces you to be specific: \"create venv\" is better than \"set up the environment.\"\n",
    "\n",
    "**`make_demo_checklist_todo()` — your task:**\n",
    "Replace the `<todo: ...>` placeholders with your actual capstone steps:\n",
    "- **Setup steps**: the exact commands to create the environment and install dependencies\n",
    "- **Run command**: the exact `python run_capstone.py ...` command with real flag values\n",
    "- **Expected outputs**: the exact file paths that should appear after a successful run\n",
    "- **Failure case**: a specific failure scenario you can demo (e.g., missing input file → clear error message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5723d8",
   "metadata": {},
   "source": [
    "## Demo readiness checklist\n",
    "\n",
    "- Setup steps start from scratch:\n",
    "  - create env\n",
    "  - install deps\n",
    "  - configure secrets\n",
    "\n",
    "- Run steps:\n",
    "  - one command\n",
    "  - expected outputs listed\n",
    "\n",
    "- Outputs:\n",
    "  - stable file paths\n",
    "  - stable schema fields\n",
    "\n",
    "- Failure case:\n",
    "  - show what happens when an input is invalid\n",
    "  - show how logs help\n",
    "\n",
    "If you have time, add one “performance realism” note:\n",
    "\n",
    "- expected runtime on your machine\n",
    "- known slow step (e.g., first model call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d07ca",
   "metadata": {},
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DemoChecklist:\n",
    "    setup_steps: List[str]\n",
    "    run_command: str\n",
    "    expected_outputs: List[str]\n",
    "    failure_case: str\n",
    "    perf_note: Optional[str] = None\n",
    "\n",
    "\n",
    "def write_readme_checklist(path: Path, checklist: DemoChecklist) -> None:\n",
    "    lines = [\"# Demo Readiness Checklist\", \"\"]\n",
    "    lines.append(\"## Setup\")\n",
    "    for s in checklist.setup_steps:\n",
    "        lines.append(\"- %s\" % s)\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"## Run\")\n",
    "    lines.append(\"- Command: `%s`\" % checklist.run_command)\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"## Expected outputs\")\n",
    "    for o in checklist.expected_outputs:\n",
    "        lines.append(\"- %s\" % o)\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"## Failure case\")\n",
    "    lines.append(\"- %s\" % checklist.failure_case)\n",
    "    if checklist.perf_note:\n",
    "        lines.append(\"\")\n",
    "        lines.append(\"## Performance note\")\n",
    "        lines.append(\"- %s\" % checklist.perf_note)\n",
    "    path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def make_demo_checklist_todo() -> DemoChecklist:\n",
    "    # TODO: customize this checklist for your capstone.\n",
    "    return DemoChecklist(\n",
    "        setup_steps=[\"<todo: create venv>\", \"<todo: install deps>\", \"<todo: set secrets>\"],\n",
    "        run_command=\"python run_capstone.py --input <INPUT.csv> --output_dir output --model <MODEL>\",\n",
    "        expected_outputs=[\"output/report.json\", \"output/report.md\"],\n",
    "        failure_case=\"Run with a missing input file and show the error message\",\n",
    "        perf_note=None,\n",
    "    )\n",
    "\n",
    "\n",
    "checklist = make_demo_checklist_todo()\n",
    "out_path = OUTPUT_DIR / \"DEMO_CHECKLIST.md\"\n",
    "write_readme_checklist(out_path, checklist)\n",
    "print(\"wrote:\", out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a0ba75",
   "metadata": {},
   "source": [
    "## Self-check\n",
    "\n",
    "- Can a teammate run your demo without asking you questions?\n",
    "- Can you demo without editing code live?\n",
    "\n",
    "## References\n",
    "\n",
    "- GitHub on READMEs: https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-readmes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d791bb97",
   "metadata": {},
   "source": [
    "## Appendix: Solutions (peek only after trying)\n",
    "\n",
    "Reference implementation for `make_demo_checklist_todo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01382d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_demo_checklist_todo() -> DemoChecklist:\n",
    "    return DemoChecklist(\n",
    "        setup_steps=[\n",
    "            \"Create venv\",\n",
    "            \"pip install -r requirements.txt\",\n",
    "            \"Set API key in .env (do not commit .env)\",\n",
    "        ],\n",
    "        run_command=\"python run_capstone.py --input output/capstone_sample.csv --output_dir output --model llama3.1\",\n",
    "        expected_outputs=[\n",
    "            \"output/report.json\",\n",
    "            \"output/report.md\",\n",
    "        ],\n",
    "        failure_case=\"Run with --input missing.csv and show the actionable error\",\n",
    "        perf_note=\"First run may be slower due to model warmup\",\n",
    "    )\n",
    "\n",
    "\n",
    "solution_path = OUTPUT_DIR / \"DEMO_CHECKLIST_solution.md\"\n",
    "write_readme_checklist(solution_path, make_demo_checklist_todo())\n",
    "print(\"wrote:\", solution_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
