{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 — Part 03: Chunking long text + synthesizing summaries\n",
    "\n",
    "**Estimated time:** 60–100 minutes\n",
    "\n",
    "## What success looks like (end of Part 03)\n",
    "\n",
    "- You can split long text into overlapping chunks deterministically.\n",
    "- You can produce a small per-chunk schema and synthesize a final summary.\n",
    "- You can show the number of chunks created and inspect at least one chunk.\n",
    "\n",
    "### Checkpoint\n",
    "\n",
    "After running this notebook, you should see:\n",
    "\n",
    "- `chunks=...` printed\n",
    "- a final synthesized summary dict printed\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Implement a simple chunking utility for long text\n",
    "- Define a per-chunk summary schema\n",
    "- Synthesize chunk outputs into a final summary\n",
    "- Understand chunk-boundary pitfalls and overlap strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f548b687",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "When text is too long for the context window:\n",
    "\n",
    "1. **Split into chunks**\n",
    "2. **Process each chunk** into a small structured summary\n",
    "3. **Synthesize** a final summary from per-chunk outputs\n",
    "\n",
    "---\n",
    "\n",
    "## Underlying theory: chunking is a strategy for bounded-context reasoning\n",
    "\n",
    "If the document is longer than what you can send at once, you have two options:\n",
    "\n",
    "- **lossy compression**: summarize first (risk losing details)\n",
    "- **chunking**: split and process pieces (risk missing cross-chunk dependencies)\n",
    "\n",
    "Chunking introduces a boundary effect: information near chunk boundaries can be separated.\n",
    "\n",
    "Practical implication: if correctness depends on cross-paragraph links, you may need overlap or a second pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d01acfe",
   "metadata": {},
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "\n",
    "def chunk_text_simple(text: str, *, chunk_size: int = 1800) -> List[str]:\n",
    "    return [text[i : i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "\n",
    "def chunk_text_overlap(text: str, *, chunk_size: int = 1800, overlap: int = 150) -> List[str]:\n",
    "    chunks: List[str] = []\n",
    "    step = max(1, chunk_size - overlap)\n",
    "    for i in range(0, len(text), step):\n",
    "        chunks.append(text[i : i + chunk_size])\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def summarize_chunk_stub(chunk: str) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"summary_bullets\": [chunk[:40] + \"...\"] if chunk else [],\n",
    "        \"key_entities\": [\"<todo>\"] if chunk else [],\n",
    "        \"open_questions\": [],\n",
    "    }\n",
    "\n",
    "\n",
    "def synthesize_summaries(summaries: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    bullets = [b for s in summaries for b in s.get(\"summary_bullets\", [])]\n",
    "    return {\"summary\": bullets[:5], \"note\": \"synthesized from chunk summaries\"}\n",
    "\n",
    "\n",
    "text = \"B\" * 4800\n",
    "chunks = chunk_text_overlap(text, chunk_size=1800, overlap=150)\n",
    "per_chunk = [summarize_chunk_stub(c) for c in chunks]\n",
    "final_summary = synthesize_summaries(per_chunk)\n",
    "print(\"chunks=\", len(chunks))\n",
    "print(final_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7f12d9",
   "metadata": {},
   "source": [
    "## Synthesis pattern (high-level)\n",
    "\n",
    "- For each chunk: ask the model for a short structured summary.\n",
    "- After all chunks: ask the model to combine those summaries.\n",
    "\n",
    "This is a simple form of hierarchical summarization:\n",
    "\n",
    "- level 1: per-chunk summaries\n",
    "- level 2: global synthesis\n",
    "\n",
    "Practical implication: enforcing a small per-chunk schema helps reduce drift and makes synthesis more reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c3cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def chunk_text_todo(text: str, chunk_size: int = 1500, overlap: int = 200) -> List[str]:\n",
    "    # TODO: implement chunking with overlap.\n",
    "    if chunk_size <= 0:\n",
    "        return []\n",
    "    if overlap < 0:\n",
    "        overlap = 0\n",
    "    step = max(1, chunk_size - overlap)\n",
    "    return [text[i : i + chunk_size] for i in range(0, len(text), step)]\n",
    "\n",
    "\n",
    "def make_chunk_prompt(chunk: str) -> str:\n",
    "    # TODO: create a prompt template for per-chunk summaries.\n",
    "    return \"\".join(\n",
    "        [\n",
    "            \"You are summarizing one chunk of a longer document.\\n\",\n",
    "            \"Return JSON with keys: summary_bullets (list of short strings), key_entities (list), open_questions (list).\\n\",\n",
    "            \"Chunk:\\n\",\n",
    "            chunk,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "_demo_chunks = chunk_text_todo(\"ABC\" * 1200, chunk_size=1500, overlap=200)\n",
    "print(\"demo_chunks=\", len(_demo_chunks))\n",
    "print(make_chunk_prompt(_demo_chunks[0])[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae57cfd",
   "metadata": {},
   "source": [
    "## Appendix: Solutions (peek only after trying)\n",
    "\n",
    "Reference implementations for the TODO functions in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01823a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text_todo(text: str, chunk_size: int = 1500, overlap: int = 200) -> List[str]:\n",
    "    if chunk_size <= 0:\n",
    "        raise ValueError(\"chunk_size must be > 0\")\n",
    "    if overlap >= chunk_size:\n",
    "        raise ValueError(\"overlap must be < chunk_size\")\n",
    "\n",
    "    step = chunk_size - overlap\n",
    "    return [text[i : i + chunk_size] for i in range(0, len(text), step)]\n",
    "\n",
    "\n",
    "def make_chunk_prompt(chunk: str) -> str:\n",
    "    return (\n",
    "        \"You are summarizing one chunk of a longer document.\\n\"\n",
    "        \"Return STRICT JSON with keys:\\n\"\n",
    "        \"- summary_bullets: list of short strings (max 3)\\n\"\n",
    "        \"- key_entities: list of strings\\n\"\n",
    "        \"- open_questions: list of strings\\n\\n\"\n",
    "        \"Chunk:\\n\"\n",
    "        + chunk\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"solution_prompt_preview=\", make_chunk_prompt(\"hello\")[:120] + \"...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
