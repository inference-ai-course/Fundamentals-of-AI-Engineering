{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations Course \u2014 Week 6 Practice (Starter Notebook)\n",
    "\n",
    "Starter Capstone pipeline skeleton: CSV -> profile -> sample/compress -> LLM placeholder -> report artifacts.\n",
    "\n",
    "## What success looks like (end of practice)\n",
    "\n",
    "- You produce `output/report.json` and `output/report.md`.\n",
    "- You can inspect `output/capstone_sample.csv` and explain how sampling/compression works.\n",
    "- You implement the TODO exercise and verify it writes an artifact under `output/`.\n",
    "\n",
    "### Checkpoint\n",
    "\n",
    "- Re-running the notebook produces the same `report.json` fields.\n",
    "- `output/capstone_sample.csv` exists.\n",
    "\n",
    "## References (docs)\n",
    "- Pandas I/O (CSV): https://pandas.pydata.org/docs/user_guide/io.html\n",
    "- Pandas sampling: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html\n",
    "- JSON Schema: https://json-schema.org/\n",
    "- Python `json`: https://docs.python.org/3/library/json.html\n",
    "- Twelve-Factor App: https://12factor.net/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Runnable without an API key because the LLM call is a placeholder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "OUTPUT_DIR = Path('output')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "OUTPUT_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Load CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'user_id': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'age': [23, None, 31, 45, 29, 35, None, 41],\n",
    "    'country': ['US', 'US', 'SG', None, 'CN', 'US', 'SG', 'CN'],\n",
    "    'purchase_amount': [12.5, 0.0, 7.99, 103.2, None, 5.0, 1000.0, 8.2],\n",
    "})\n",
    "csv_path = OUTPUT_DIR / 'capstone_sample.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_df(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    return {\n",
    "        'n_rows': int(df.shape[0]),\n",
    "        'n_cols': int(df.shape[1]),\n",
    "        'dtypes': {k: str(v) for k, v in df.dtypes.items()},\n",
    "        'missing_by_col': df.isna().sum().to_dict(),\n",
    "        'duplicate_rows': int(df.duplicated().sum()),\n",
    "        'numeric_stats': df.select_dtypes(include='number').describe().to_dict(),\n",
    "    }\n",
    "\n",
    "profile = profile_df(df)\n",
    "profile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Sample/compress input for the LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_llm_input(df: pd.DataFrame, profile: Dict[str, Any], sample_n: int = 5) -> Dict[str, Any]:\n",
    "    sample = df.sample(n=min(sample_n, len(df)), random_state=42).to_dict(orient='records')\n",
    "    anomalies: List[Dict[str, Any]] = []\n",
    "    if 'purchase_amount' in df.columns:\n",
    "        s = df['purchase_amount'].dropna()\n",
    "        if len(s) > 0:\n",
    "            threshold = float(s.quantile(0.95))\n",
    "            for _, row in df[df['purchase_amount'].fillna(-1) > threshold].iterrows():\n",
    "                anomalies.append({'reason': 'purchase_amount above 95th percentile ({:.2f})'.format(threshold), 'row': row.to_dict()})\n",
    "    return {\n",
    "        'profile_summary': {\n",
    "            'n_rows': profile['n_rows'],\n",
    "            'n_cols': profile['n_cols'],\n",
    "            'missing_by_col': profile['missing_by_col'],\n",
    "            'dtypes': profile['dtypes'],\n",
    "        },\n",
    "        'numeric_stats': profile['numeric_stats'],\n",
    "        'sample_rows': sample,\n",
    "        'anomalies': anomalies,\n",
    "    }\n",
    "\n",
    "llm_input = make_llm_input(df, profile, sample_n=5)\n",
    "llm_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: LLM explanation (placeholder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_explain_placeholder(llm_input: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    return {\n",
    "        'insights': [\n",
    "            'Missing values exist in age/country/purchase_amount; decide whether to impute or drop.',\n",
    "            'High purchase_amount outliers may indicate VIP customers or data issues.',\n",
    "        ],\n",
    "        'recommendations': [\n",
    "            'Add input validation for required columns before analysis.',\n",
    "            'Track missing value rates over time as a data quality metric.',\n",
    "            'Investigate outliers with row-level drill-down and source validation.',\n",
    "        ],\n",
    "        'risk_notes': [\n",
    "            'Small samples may not represent the full dataset; confirm with stratified sampling if needed.',\n",
    "        ],\n",
    "    }\n",
    "\n",
    "llm_explanation = llm_explain_placeholder(llm_input)\n",
    "llm_explanation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Write report artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReportPaths:\n",
    "    report_json: Path\n",
    "    report_md: Path\n",
    "\n",
    "def build_report(profile: Dict[str, Any], llm_explanation: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    return {\n",
    "        'data_overview': {\n",
    "            'n_rows': profile['n_rows'],\n",
    "            'n_cols': profile['n_cols'],\n",
    "            'dtypes': profile['dtypes'],\n",
    "            'missing_by_col': profile['missing_by_col'],\n",
    "        },\n",
    "        'anomalies': llm_input.get('anomalies', []),\n",
    "        'insights': llm_explanation.get('insights', []),\n",
    "        'recommendations': llm_explanation.get('recommendations', []),\n",
    "        'risk_notes': llm_explanation.get('risk_notes', []),\n",
    "    }\n",
    "\n",
    "def write_report(report: Dict[str, Any], out_dir: Path) -> ReportPaths:\n",
    "    report_json = out_dir / 'report.json'\n",
    "    report_md = out_dir / 'report.md'\n",
    "    report_json.write_text(json.dumps(report, ensure_ascii=False, indent=2), encoding='utf-8')\n",
    "    md_lines = [\n",
    "        '# Report',\n",
    "        '',\n",
    "        '## Data Overview',\n",
    "        'Rows: {}'.format(report['data_overview']['n_rows']),\n",
    "        'Cols: {}'.format(report['data_overview']['n_cols']),\n",
    "        '',\n",
    "        '## Insights',\n",
    "    ]\n",
    "    for it in report.get('insights', []):\n",
    "        md_lines.append('- ' + str(it))\n",
    "    md_lines.extend(['', '## Recommendations'])\n",
    "    for it in report.get('recommendations', []):\n",
    "        md_lines.append('- ' + str(it))\n",
    "    md_lines.extend(['', '## Risk Notes'])\n",
    "    for it in report.get('risk_notes', []):\n",
    "        md_lines.append('- ' + str(it))\n",
    "    report_md.write_text('\\n'.join(md_lines), encoding='utf-8')\n",
    "    return ReportPaths(report_json=report_json, report_md=report_md)\n",
    "\n",
    "report = build_report(profile, llm_explanation)\n",
    "paths = write_report(report, OUTPUT_DIR)\n",
    "paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise (TODO)\n",
    "\n",
    "Add a required-columns guard before running the pipeline.\n",
    "\n",
    "Goal:\n",
    "\n",
    "- Implement `assert_required_columns_todo(df, required)`.\n",
    "- Save the check result under `output/required_columns.json`.\n",
    "\n",
    "Checkpoint:\n",
    "\n",
    "- Calling the function with a missing column raises a clear `ValueError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_required_columns_todo(df: pd.DataFrame, required: List[str]) -> None:\n",
    "    # TODO: implement\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(\"missing required columns: %s\" % missing)\n",
    "\n",
    "\n",
    "required_cols = [\"user_id\", \"age\", \"country\", \"purchase_amount\"]\n",
    "assert_required_columns_todo(df, required_cols)\n",
    "\n",
    "(OUTPUT_DIR / \"required_columns.json\").write_text(\n",
    "    json.dumps({\"required\": required_cols, \"present\": list(df.columns)}, indent=2),\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(\"wrote:\", OUTPUT_DIR / \"required_columns.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3622a3bf",
   "metadata": {},
   "source": [
    "## Appendix: Solutions (peek only after trying)\n",
    "\n",
    "Reference implementation for `assert_required_columns_todo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae76f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_required_columns_todo(df: pd.DataFrame, required: List[str]) -> None:\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(\"missing required columns: %s\" % missing)\n",
    "\n",
    "\n",
    "try:\n",
    "    assert_required_columns_todo(df.drop(columns=[\"country\"]), required_cols)\n",
    "except ValueError as e:\n",
    "    (OUTPUT_DIR / \"required_columns_failure.json\").write_text(\n",
    "        json.dumps({\"error\": str(e)}, indent=2),\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "    print(\"wrote:\", OUTPUT_DIR / \"required_columns_failure.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}