{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 — Part 02: Structured Prompt Specification\n",
    "\n",
    "**Estimated time:** 60–90 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Pre-study (Self-learn)\n",
    "\n",
    "Foundations Course assumes Self-learn is complete. If you need a refresher:\n",
    "\n",
    "- [Foundations Course Pre-study index](../PRESTUDY.md)\n",
    "- [Self-learn — Prompt engineering and evaluation](../self_learn/Chapters/3/02_prompt_engineering_evaluation.md)\n",
    "- [Self-learn — Structured outputs and schemas](../self_learn/Chapters/3/01_function_calling_structured_outputs.md)\n",
    "\n",
    "---\n",
    "\n",
    "## What success looks like (end of Part 02)\n",
    "\n",
    "- You can write a prompt that acts like a contract: explicit keys, explicit constraints, and clear handling for missing data.\n",
    "- You can validate a model's output deterministically (parse + schema checks).\n",
    "\n",
    "### Checkpoint\n",
    "\n",
    "- You can run `parse_contract_output(...)` on at least 2 simulated outputs.\n",
    "- Your prompt explicitly bans extra keys and non-JSON text.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Treat prompts as specifications (contracts)\n",
    "- Define clear preconditions and postconditions\n",
    "- Design strict JSON output contracts\n",
    "- Create validators that make outputs checkable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85170731",
   "metadata": {},
   "source": [
    "### What this part covers\n",
    "This notebook teaches you to treat prompts as **API contracts** — not as \"clever wording\" but as formal specifications with:\n",
    "- a defined input format\n",
    "- an exact output schema (JSON keys, types)\n",
    "- explicit constraints (no extra keys, no markdown, no prose)\n",
    "- fallback conditions (what to return when the answer is unknown)\n",
    "\n",
    "**Why this matters:** A vague prompt produces unpredictable output. A contract prompt produces output you can validate programmatically — which is essential for building reliable pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a53bd",
   "metadata": {},
   "source": [
    "## What is a Prompt?\n",
    "\n",
    "A **prompt** is the input text or instructions you send to a Large Language Model (LLM). It acts as the API contract between your code and the AI.\n",
    "\n",
    "Typically, when using an LLM API (like OpenAI's), a prompt is broken down into structured roles:\n",
    "- **System**: High-level instructions, persona, and rules (e.g., \"You are a helpful Python expert. Always return JSON\").\n",
    "- **User**: The specific request, task, or data the user wants processed.\n",
    "\n",
    "Let's look at a basic example of how to construct and send a prompt using the OpenAI API format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cfffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Make sure you have a .env file with your OPENAI_API_KEY\n",
    "load_dotenv()\n",
    "\n",
    "# We initialize the client\n",
    "client = OpenAI()\n",
    "\n",
    "def call_llm(system_prompt: str, user_prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    A basic wrapper around an LLM API call demonstrating 'What is a Prompt?'.\n",
    "    We separate the 'System' (rules/persona) from the 'User' (task/data).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.0 # Keep it deterministic\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error calling API: {e}\"\n",
    "\n",
    "# Example of a System Prompt (the \"Contract\")\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful Python expert. \n",
    "Your goal is to explain concepts clearly to beginners.\n",
    "\"\"\"\n",
    "\n",
    "# Example of a User Prompt (the \"Input\")\n",
    "user_prompt = \"Explain what a Python dictionary is in one sentence.\"\n",
    "\n",
    "# Let's run it\n",
    "output = call_llm(system_prompt, user_prompt)\n",
    "print(\"=== LLM Response ===\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6417705",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this lab, you will practice writing prompts as **checkable specs**.\n",
    "\n",
    "You will:\n",
    "\n",
    "- write a strict JSON “contract prompt”\n",
    "- validate outputs deterministically (parse + exact key checks)\n",
    "- extend the contract with a refusal/error shape (TODO)\n",
    "\n",
    "If you need the conceptual background, use the Self-learn links at the top of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe1758",
   "metadata": {},
   "source": [
    "### What this cell does\n",
    "Defines the core validation infrastructure:\n",
    "\n",
    "- **`Extracted` dataclass** — the typed output schema. `person` and `company` are both `Optional[str]` — they can be `null` when the model can't find them.\n",
    "- **`validate_exact_keys()`** — checks that the JSON has *exactly* the required keys: no missing, no extra. Extra keys are a contract violation just as much as missing keys.\n",
    "- **`parse_contract_output()`** — the full parse + validate pipeline: JSON parse → key check → type check → typed result.\n",
    "\n",
    "**Key insight:** Separating parse from validate from type-check gives you precise error messages. \"Missing keys: ['company']\" tells you exactly what went wrong and where to fix the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ed7f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Set\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Extracted:\n",
    "    person: Optional[str]\n",
    "    company: Optional[str]\n",
    "\n",
    "\n",
    "def validate_exact_keys(obj: dict, required_keys: Set[str]) -> None:\n",
    "    extra = set(obj.keys()) - required_keys\n",
    "    missing = required_keys - set(obj.keys())\n",
    "    if missing:\n",
    "        raise ValueError(f\"missing keys: {sorted(missing)}\")\n",
    "    if extra:\n",
    "        raise ValueError(f\"extra keys: {sorted(extra)}\")\n",
    "\n",
    "\n",
    "def parse_contract_output(text: str) -> Extracted:\n",
    "    data = json.loads(text)\n",
    "    if not isinstance(data, dict):\n",
    "        raise ValueError(\"output must be a JSON object\")\n",
    "    validate_exact_keys(data, {\"person\", \"company\"})\n",
    "\n",
    "    person = data.get(\"person\")\n",
    "    company = data.get(\"company\")\n",
    "\n",
    "    if person is not None and not isinstance(person, str):\n",
    "        raise ValueError(\"person must be string or null\")\n",
    "    if company is not None and not isinstance(company, str):\n",
    "        raise ValueError(\"company must be string or null\")\n",
    "\n",
    "    return Extracted(person=person, company=company)\n",
    "\n",
    "\n",
    "print(parse_contract_output('{\"person\": \"Ada\", \"company\": null}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd288eb",
   "metadata": {},
   "source": [
    "### What this cell does\n",
    "Defines `build_extraction_prompt()` — a function that constructs a strict contract prompt from input text.\n",
    "\n",
    "**Notice the structure of the prompt:**\n",
    "1. **Role** — tells the model what it is doing\n",
    "2. **Task** — what to produce\n",
    "3. **Output format** — ONLY JSON, exact keys listed\n",
    "4. **Rules** — no markdown, no extra keys, use null when missing\n",
    "5. **Input** — the actual text to process\n",
    "\n",
    "**Why explicit rules matter:** Without \"no markdown\", the model might wrap the JSON in a code block (` ```json ... ``` `). Without \"use null when missing\", it might hallucinate a value. Each rule closes a specific failure mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e790749",
   "metadata": {},
   "source": [
    "## Exercise: Write a contract prompt\n",
    "\n",
    "Below is a contract prompt template. Your job is to adjust it for new tasks while keeping it checkable.\n",
    "\n",
    "Key properties:\n",
    "\n",
    "- “Return ONLY valid JSON”\n",
    "- “exactly these keys”\n",
    "- “Use null if not found”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf1f65e",
   "metadata": {},
   "source": [
    "### What this cell does\n",
    "Defines `simulate_model_output()` — a stand-in for a real LLM call — then runs the full contract pipeline: build prompt → simulate output → parse and validate.\n",
    "\n",
    "**Why use a simulator?** You can test your parsing and validation logic without making real API calls (which cost money and require a key). Once the contract logic is solid, swapping in a real LLM call is a one-line change.\n",
    "\n",
    "**Your task:** Implement `build_refusal_contract_todo()` — extend the contract to return either `{\"ok\": true, ...}` or `{\"ok\": false, \"error\": \"...\"}`. This \"refusal shape\" is important: it lets downstream code distinguish \"extraction succeeded\" from \"extraction was impossible\" without relying on null-checking heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a104f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_extraction_prompt(text: str) -> str:\n",
    "    # Non-verbatim: same idea, slightly different wording and ordering.\n",
    "    return (\n",
    "        \"Role: Information extraction engine.\\n\"\n",
    "        \"Task: Extract a person name and a company name.\\n\"\n",
    "        \"Output: ONLY JSON with keys person, company.\\n\"\n",
    "        \"Rules: no markdown, no additional keys, use null when missing.\\n\\n\"\n",
    "        f\"Input text:\\n{text}\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(build_extraction_prompt(\"Ada Lovelace founded nothing.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9ab7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_model_output(prompt: str) -> str:\n",
    "    # Simulated outputs for practice (stand-in for real LLM call)\n",
    "    if \"Ada\" in prompt:\n",
    "        return '{\"person\": \"Ada Lovelace\", \"company\": null}'\n",
    "    return '{\"person\": null, \"company\": null}'\n",
    "\n",
    "\n",
    "raw = simulate_model_output(build_extraction_prompt(\"Ada Lovelace wrote notes.\"))\n",
    "print(\"raw:\", raw)\n",
    "print(\"parsed:\", parse_contract_output(raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adcbe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_refusal_contract_todo(text: str) -> str:\n",
    "    \"\"\"TODO: extend the contract to return either:\n",
    "\n",
    "    - {\"ok\": true, \"person\": ..., \"company\": ...}\n",
    "    - OR {\"ok\": false, \"error\": \"...\"}\n",
    "\n",
    "    Keep it strict:\n",
    "\n",
    "    - return ONLY JSON\n",
    "    - no additional keys\n",
    "    - use null for missing fields when ok=true\n",
    "    \"\"\"\n",
    "    return (\n",
    "        \"Role: Information extraction engine.\\n\"\n",
    "        \"Task: Extract a person name and a company name.\\n\"\n",
    "        \"Output: ONLY JSON with exactly these keys: ok, person, company, error.\\n\"\n",
    "        \"Rules: no markdown, no additional keys.\\n\"\n",
    "        \"Rules: if extraction is possible, set ok=true, set error=null.\\n\"\n",
    "        \"Rules: if extraction is not possible, set ok=false, set person=null, company=null, and set error to a short reason.\\n\\n\"\n",
    "        f\"Input text:\\n{text}\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(build_refusal_contract_todo(\"Ada Lovelace wrote notes.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473d155d",
   "metadata": {},
   "source": [
    "## Self-check\n",
    "\n",
    "- Does your prompt define exact keys?\n",
    "- Does it forbid extra text?\n",
    "- Does it define what to do when info is missing?\n",
    "\n",
    "## References\n",
    "\n",
    "- Prompting guide: https://www.promptingguide.ai/\n",
    "- Anthropic cookbook: https://github.com/anthropics/anthropic-cookbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59cd2d",
   "metadata": {},
   "source": [
    "## Appendix: Solutions (peek only after trying)\n",
    "\n",
    "Reference implementation for `build_refusal_contract_todo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e3026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_refusal_contract_todo(text: str) -> str:\n",
    "    return (\n",
    "        \"Role: Information extraction engine.\\n\"\n",
    "        \"Task: Extract a person name and a company name.\\n\"\n",
    "        \"Return ONLY valid JSON.\\n\"\n",
    "        \"Output schema (exact keys): ok, person, company, error\\n\"\n",
    "        \"Constraints: no markdown, no prose, no extra keys.\\n\"\n",
    "        \"If a value is missing, use null.\\n\"\n",
    "        \"If you cannot comply, return ok=false and a short error message.\\n\\n\"\n",
    "        f\"INPUT:\\n{text}\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(build_refusal_contract_todo(\"No names here.\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
