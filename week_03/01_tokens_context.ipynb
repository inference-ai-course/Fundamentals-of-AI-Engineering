{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 — Part 01: Tokens and Context Windows Lab\n",
    "\n",
    "**Estimated time:** 90–120 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Pre-study (Self-learn)\n",
    "\n",
    "Foundations Course assumes Self-learn is complete. If you need a refresher on tokenization and prompt engineering:\n",
    "\n",
    "- [Foundations Course Pre-study index](../PRESTUDY.md)\n",
    "- [Self-learn — Prompt engineering and evaluation](../self_learn/Chapters/3/02_prompt_engineering_evaluation.md)\n",
    "\n",
    "---\n",
    "\n",
    "## What success looks like (end of Part 01)\n",
    "\n",
    "- You can estimate token counts for a given text.\n",
    "- You can explain why long prompts fail (context window limits).\n",
    "- You can design prompts that fit within limits.\n",
    "\n",
    "### Checkpoint\n",
    "\n",
    "After running this notebook:\n",
    "- You can measure prompt size in tokens\n",
    "- You can identify when a prompt exceeds typical context limits\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand tokenization basics\n",
    "- Measure token counts in prompts\n",
    "- Design prompts for context window constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2077ec7c",
   "metadata": {},
   "source": [
    "### What this part covers\n",
    "This notebook builds **practical intuition about tokens and context windows** — the two most important constraints when working with LLM APIs.\n",
    "\n",
    "**Token** = the unit an LLM processes. Not a word, not a character — something in between (roughly 4 characters per token for English).\n",
    "\n",
    "**Context window** = the maximum number of tokens per request. If your prompt + expected output exceeds this limit, the request fails or the model truncates its output.\n",
    "\n",
    "**Why this matters immediately:** Every API call you make has a token budget. Exceeding it causes failures. Staying well within it reduces cost and latency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b994fc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This lab is about budgeting context so your prompts and structured outputs don’t fail unexpectedly.\n",
    "\n",
    "You will:\n",
    "\n",
    "- compare token counts across inputs\n",
    "- implement a simple truncation strategy\n",
    "- build a small token-budget summary helper (TODO)\n",
    "\n",
    "If you need more background on why prompts fail under long context, use the Self-learn links at the top of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80bbd13",
   "metadata": {},
   "source": [
    "### What this cell does\n",
    "Defines two tokenizers and compares them:\n",
    "\n",
    "- **`simple_tokenize()`** — a regex-based approximation. Fast, no dependencies, but not what LLMs actually use.\n",
    "- **`tiktoken`** — OpenAI's actual tokenizer. Gives exact counts for GPT models.\n",
    "\n",
    "**Key insight:** `simple_tokenize` and `tiktoken` will give different counts for the same text. The difference matters when you're budgeting prompts — always use the model's actual tokenizer for production code.\n",
    "\n",
    "**If tiktoken is not installed:** Run `pip install tiktoken` in your environment. The notebook will still run without it (the `try/except` handles the missing import gracefully)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5f11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "try:\n",
    "    import tiktoken\n",
    "except Exception as e:  # pragma: no cover\n",
    "    tiktoken = None\n",
    "    _tiktoken_error = e\n",
    "\n",
    "\n",
    "def simple_tokenize(text: str) -> List[str]:\n",
    "    return re.findall(r\"\\w+|[^\\w\\s]\", text)\n",
    "\n",
    "\n",
    "sample = \"Hello, world! Token test.\"\n",
    "print(\"simple tokens:\", simple_tokenize(sample))\n",
    "\n",
    "if tiktoken is None:\n",
    "    print(\"tiktoken not available:\", _tiktoken_error)\n",
    "else:\n",
    "    # Note: cl100k_base is used by gpt-4 (non-turbo) and gpt-3.5-turbo.\n",
    "    # Newer models (gpt-4o, gpt-4o-mini) use o200k_base.\n",
    "    # Use tiktoken.encoding_for_model(\"<model_name>\") to get the correct encoding automatically.\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = enc.encode(\"Token counting is useful for budgeting.\")\n",
    "    print(\"tiktoken count (cl100k_base):\", len(tokens))\n",
    "    print(\"Tip: for gpt-4o / gpt-4o-mini, use tiktoken.encoding_for_model('gpt-4o') → o200k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52acb222",
   "metadata": {},
   "source": [
    "### What this cell does\n",
    "Implements `truncate_text_tokens()` — a function that cuts text to fit within a maximum token budget by encoding to tokens, slicing, then decoding back to text.\n",
    "\n",
    "**Why truncate at the token level, not character level?** Characters and tokens don't have a fixed ratio. Truncating at 800 characters might give you 150 tokens or 400 tokens depending on the content. Token-level truncation gives you precise control over the budget.\n",
    "\n",
    "**Practical use:** In Week 6, you'll compress tabular data before sending it to an LLM. This truncation pattern is one tool in that toolkit — useful when you have a block of text that might be too long."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b1919",
   "metadata": {},
   "source": [
    "## Truncation exercise\n",
    "\n",
    "Use a simple truncation strategy to fit text into a max token budget."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dbff55",
   "metadata": {},
   "source": [
    "### What this cell does\n",
    "Defines `token_budget_summary_todo()` — a helper that returns both a simple token count and a tiktoken count for any text.\n",
    "\n",
    "**Your task:** The current implementation returns `None` for `n_tiktoken_tokens`. Implement it to return the real tiktoken count when tiktoken is available, and `None` when it's not.\n",
    "\n",
    "**Why both counts?** The simple tokenizer is always available (no dependencies), so it's useful as a quick estimate. The tiktoken count is exact for OpenAI models. Having both lets you see how much the approximation differs from reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ae50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_text_tokens(text: str, max_tokens: int, *, enc) -> str:\n",
    "    tokens = enc.encode(text)\n",
    "    if len(tokens) <= max_tokens:\n",
    "        return text\n",
    "    return enc.decode(tokens[:max_tokens])\n",
    "\n",
    "\n",
    "if tiktoken is not None:\n",
    "    long_text = \"data \" * 400\n",
    "    truncated = truncate_text_tokens(long_text, 200, enc=enc)\n",
    "    print(\"orig tokens:\", len(enc.encode(long_text)))\n",
    "    print(\"trunc tokens:\", len(enc.encode(truncated)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ec933c",
   "metadata": {},
   "source": [
    "## Exercise: token budgeting helper (TODO)\n",
    "\n",
    "Implement the TODO function below.\n",
    "\n",
    "Goal:\n",
    "\n",
    "- Given a piece of text, return a dict containing:\n",
    "  - `n_simple_tokens` using `simple_tokenize`\n",
    "  - `n_tiktoken_tokens` if `tiktoken` is available, otherwise `None`\n",
    "\n",
    "Checkpoint:\n",
    "\n",
    "- Running the cell prints token counts for at least 2 inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe04a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_budget_summary_todo(text: str) -> dict:\n",
    "    # TODO: implement.\n",
    "    # Keep it runnable even if tiktoken is not installed.\n",
    "    return {\"n_simple_tokens\": len(simple_tokenize(text)), \"n_tiktoken_tokens\": None}\n",
    "\n",
    "\n",
    "examples = [\n",
    "    \"Hello world!\",\n",
    "    \"https://example.com/some/path?with=query&and=more\",\n",
    "]\n",
    "\n",
    "for s in examples:\n",
    "    print(s, \"->\", token_budget_summary_todo(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e17957",
   "metadata": {},
   "source": [
    "## Appendix: Solutions (peek only after trying)\n",
    "\n",
    "Reference implementation for `token_budget_summary_todo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_budget_summary_todo(text: str) -> dict:\n",
    "    n_simple = len(simple_tokenize(text))\n",
    "\n",
    "    if tiktoken is None:\n",
    "        return {\"n_simple_tokens\": n_simple, \"n_tiktoken_tokens\": None}\n",
    "\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    n_tiktoken = len(enc.encode(text))\n",
    "    return {\"n_simple_tokens\": n_simple, \"n_tiktoken_tokens\": int(n_tiktoken)}\n",
    "\n",
    "\n",
    "for s in examples:\n",
    "    print(s, \"->\", token_budget_summary_todo(s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
