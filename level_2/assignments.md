# Level 2 作业与评测（Assignments & Assessment）

## 提交规范（建议）

*   每次作业提交必须包含：
    *   可运行方式（README + 命令）
    *   关键配置说明（env vars / config file）
    *   日志样例（能定位阶段）
*   每次作业都要求至少 1 个“失败路径”说明：你如何发现、定位、修复

## 作业列表（建议 6 次 + 1 个 Capstone）

### B1：FastAPI 服务骨架（工程最小集）

*   **目标**：把 AI 应用放进“可服务化”的工程骨架
*   **要求**：health check、结构化日志、请求 ID、基础错误处理
*   **验收**：启动说明清晰；错误输入返回可理解信息

### B2：RAG 数据导入管线（ETL/Indexing）

*   **目标**：让知识库可维护、可更新
*   **要求**：实现 `ingest.py` 支持增量导入（策略说明即可，不强制完全实现）
*   **验收**：重复导入不会造成明显重复污染（可用去重/版本号/哈希等方式）

### B3：Chunking 对比实验

*   **目标**：理解 chunking 对检索质量的影响
*   **要求**：实现两种 chunking 方案并对比；产出对比报告
*   **验收**：报告需包含失败样例与原因推测

### B4：RAG v1（引用溯源 + 拒答/澄清）

*   **目标**：让回答“可解释且可控”
*   **要求**：回答必须带引用；上下文不足时拒答或提出澄清问题
*   **验收**：提供 5 个测试问题，包含“库内/库外/边界”三类

### B5：最小评测集 + 评测脚本

*   **目标**：建立质量基线与迭代依据
*   **要求**：20-50 条 QA；脚本输出至少 2 个指标（例如命中率/引用覆盖率）
*   **验收**：评测可复现，能输出失败样例列表

### B6：Agent Workflow（工具调用 + 失败恢复）

*   **目标**：让系统具备行动能力
*   **要求**：至少 2 个工具（例如 search/summarize/write）；失败可降级
*   **验收**：给出 3 个任务用例与运行日志，展示失败恢复效果

---

## Capstone

Capstone 要求见 [capstone.md](capstone.md)
