{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Level 2 - Week 3 - 02 Filters and Top-K Tradeoffs\n",
        "\n",
        "**Estimated time:** 60-90 minutes\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- Compare precision and recall tradeoffs\n",
        "- Understand filter impact\n",
        "- Log retrieval settings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n",
        "\n",
        "Filters improve precision, `top_k` improves recall.\n",
        "\n",
        "### Underlying theory: precision@k and recall@k\n",
        "\n",
        "Let:\n",
        "\n",
        "- $R$ be the set of relevant chunk ids for a query\n",
        "- $L_k = [\\ell_1, \\ldots, \\ell_k]$ be the ordered list of retrieved chunk ids\n",
        "- $\\text{hits}_k = R \\cap \\{\\ell_1, \\ldots, \\ell_k\\}$\n",
        "\n",
        "Then:\n",
        "\n",
        "$$\n",
        "\\mathrm{Precision@k} = \\frac{|\\text{hits}_k|}{k}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathrm{Recall@k} = \\frac{|\\text{hits}_k|}{|R|}\n",
        "$$\n",
        "\n",
        "Intuition:\n",
        "\n",
        "- Precision@k is “how noisy are the retrieved chunks?”\n",
        "- Recall@k is “did I get the evidence I needed at all?”\n",
        "\n",
        "### Filters as restricting the search space\n",
        "\n",
        "A filter restricts the candidate set from “all chunks” to “chunks matching this predicate”.\n",
        "\n",
        "- correct filters can remove irrelevant regions and improve precision\n",
        "- wrong filters can remove all relevant chunks and collapse recall to 0\n",
        "\n",
        "## Practice Steps\n",
        "\n",
        "- Compute precision and recall for toy results.\n",
        "- Compare two `top_k` settings.\n",
        "- Change retrieved lists to simulate different filter outcomes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sample code\n",
        "\n",
        "Toy precision and recall calculation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def precision_at_k(relevant: set[str], retrieved: list[str]) -> float:\n",
        "    if not retrieved:\n",
        "        return 0.0\n",
        "    hits = [r for r in retrieved if r in relevant]\n",
        "    return len(hits) / len(retrieved)\n",
        "\n",
        "\n",
        "def recall_at_k(relevant: set[str], retrieved: list[str]) -> float:\n",
        "    if not relevant:\n",
        "        return 0.0\n",
        "    hits = [r for r in retrieved if r in relevant]\n",
        "    return len(hits) / len(relevant)\n",
        "\n",
        "relevant = {'A', 'B', 'C', 'D'}\n",
        "retrieved_3 = ['A', 'B', 'X']\n",
        "retrieved_8 = ['A', 'B', 'X', 'Y', 'C', 'Z', 'W', 'V']\n",
        "\n",
        "print('p@3', precision_at_k(relevant, retrieved_3))\n",
        "print('r@3', recall_at_k(relevant, retrieved_3))\n",
        "print('p@8', precision_at_k(relevant, retrieved_8))\n",
        "print('r@8', recall_at_k(relevant, retrieved_8))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Student fill-in\n",
        "\n",
        "Try a different filter or top_k and record the tradeoff.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def precision_at_k(relevant: set[str], retrieved: list[str], k: int) -> float:\n",
        "    topk = retrieved[:k]\n",
        "    if k <= 0:\n",
        "        raise ValueError(\"k must be > 0\")\n",
        "    if not topk:\n",
        "        return 0.0\n",
        "    hits = [r for r in topk if r in relevant]\n",
        "    return len(hits) / k\n",
        "\n",
        "\n",
        "def recall_at_k(relevant: set[str], retrieved: list[str], k: int) -> float:\n",
        "    topk = retrieved[:k]\n",
        "    if not relevant:\n",
        "        return 0.0\n",
        "    hits = [r for r in topk if r in relevant]\n",
        "    return len(hits) / len(relevant)\n",
        "\n",
        "\n",
        "def summarize_case(name: str, relevant: set[str], retrieved: list[str], k: int) -> None:\n",
        "    p = precision_at_k(relevant, retrieved, k)\n",
        "    r = recall_at_k(relevant, retrieved, k)\n",
        "    hits = [cid for cid in retrieved[:k] if cid in relevant]\n",
        "    print(name)\n",
        "    print(\"  k=\", k)\n",
        "    print(\"  retrieved=\", retrieved[:k])\n",
        "    print(\"  hits=\", hits)\n",
        "    print(\"  precision@k=\", round(p, 3), \"recall@k=\", round(r, 3))\n",
        "    print(\"---\")\n",
        "\n",
        "\n",
        "# Relevant chunks for this query (ground truth)\n",
        "relevant = {\"A\", \"B\", \"C\", \"D\"}\n",
        "\n",
        "# Case A: correct filter, small top_k => higher precision, lower recall\n",
        "retrieved_case_a = [\"A\", \"B\", \"X\"]\n",
        "\n",
        "# Case B: correct filter, larger top_k => recall improves, precision drops\n",
        "retrieved_case_b = [\"A\", \"B\", \"X\", \"Y\", \"C\", \"Z\", \"W\", \"V\"]\n",
        "\n",
        "# Case C: wrong filter => retrieved from irrelevant subset => recall collapses\n",
        "retrieved_case_c = [\"P\", \"Q\", \"R\", \"S\", \"T\", \"U\"]\n",
        "\n",
        "summarize_case(\"Case A (correct filter, k=3)\", relevant, retrieved_case_a, k=3)\n",
        "summarize_case(\"Case B (correct filter, k=8)\", relevant, retrieved_case_b, k=8)\n",
        "summarize_case(\"Case C (wrong filter, k=3)\", relevant, retrieved_case_c, k=3)\n",
        "\n",
        "# Student prompt:\n",
        "# - Modify retrieved_case_a/b/c to simulate your own scenarios\n",
        "# - Add a case where top_k is high but only 1 relevant chunk appears early (good MRR but low recall)\n",
        "# - Write down what you'd log per request: top_k, filters, returned chunk_ids+scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Self-check\n",
        "\n",
        "- Do you log filters and top_k per request?\n",
        "- Can you explain precision vs recall tradeoffs?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
