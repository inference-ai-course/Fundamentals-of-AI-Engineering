{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Level 2 - Week 3 - 01 Retrieval as API\n",
        "\n",
        "**Estimated time:** 60-90 minutes\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- Define /search contract\n",
        "- Use typed request validation\n",
        "- Keep response fields debuggable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n",
        "\n",
        "Retrieval should be a first-class endpoint.\n",
        "Typed models make failures consistent.\n",
        "\n",
        "## Practice Steps\n",
        "\n",
        "- Implement SearchRequest and SearchResponse.\n",
        "- Stub the search handler.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sample code\n",
        "\n",
        "Minimal Pydantic models with constraints.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Dict, List\n",
        "\n",
        "class SearchRequest(BaseModel):\n",
        "    query: str = Field(min_length=1)\n",
        "    top_k: int = Field(default=5, ge=1, le=50)\n",
        "    filters: Dict | None = None\n",
        "\n",
        "class SearchHit(BaseModel):\n",
        "    doc_id: str\n",
        "    chunk_id: str\n",
        "    score: float\n",
        "    text: str\n",
        "    metadata: Dict\n",
        "\n",
        "class SearchResponse(BaseModel):\n",
        "    query: str\n",
        "    hits: List[SearchHit]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Student fill-in\n",
        "\n",
        "Add a stub search handler that returns empty hits.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def search_handler(req: SearchRequest) -> SearchResponse:\n",
        "    # TODO: replace with real vector DB query\n",
        "    return SearchResponse(query=req.query, hits=[])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Self-check\n",
        "\n",
        "- Do request fields have validation?\n",
        "- Does response include chunk_id and metadata?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Legacy practice content from practice.ipynb\n\n",
        "# Level 2 \u2014 Week 3 Practice: Retrieval API + Metrics\n",
        "\n",
        "**Estimated time:** 60\u201390 minutes\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- Define retrieval API request/response contracts\n",
        "- Return top-k hits with metadata and scores\n",
        "- Add lightweight retrieval metrics for debugging\n",
        "- Keep responses stable and testable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Legacy practice content from practice.ipynb\n\n",
        "## Overview\n",
        "\n",
        "This practice focuses on the **retrieval contract**. Your goal is to define\n",
        "clear request/response models and add minimal metrics for debugging retrieval.\n",
        "\n",
        "You will:\n",
        "\n",
        "1. Define `/search` request/response schemas.\n",
        "2. Create a stub retrieval function that returns top-k hits.\n",
        "3. Add metrics (hit count, score stats) for quick inspection.\n",
        "\n",
        "## Practice Steps\n",
        "\n",
        "- Fill in the Pydantic models below.\n",
        "- Implement a fake retrieval that returns deterministic data.\n",
        "- Compute summary metrics and print them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Legacy practice content\n",
        "### Task 3.1: Retrieval API models\n",
        "\n",
        "Define request/response models for search. Keep explicit types and defaults.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f69f1a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Legacy practice content\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "class SearchRequest(BaseModel):\n",
        "    query: str\n",
        "    top_k: int = 5\n",
        "    filters: Optional[Dict] = None\n",
        "\n",
        "class SearchHit(BaseModel):\n",
        "    chunk_id: str\n",
        "    doc_id: str\n",
        "    score: float\n",
        "    text: str\n",
        "    metadata: Dict\n",
        "\n",
        "class SearchResponse(BaseModel):\n",
        "    hits: List[SearchHit]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ae5c4c3",
      "metadata": {},
      "source": [
        "Legacy practice content from practice.ipynb\n\n",
        "### Task 3.2: Stub retrieval function\n",
        "\n",
        "Create a deterministic retrieval function that returns top-k hits.\n",
        "Keep it stable so you can write tests later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a594dc01",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Legacy practice content\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def retrieve_stub(query: str, top_k: int = 5) -> List[SearchHit]:\n",
        "    # TODO: replace with real vector search\n",
        "    hits = []\n",
        "    for i in range(top_k):\n",
        "        hits.append(\n",
        "            SearchHit(\n",
        "                chunk_id=f\"chunk-{i}\",\n",
        "                doc_id=f\"doc-{i % 2}\",\n",
        "                score=1.0 - (i * 0.1),\n",
        "                text=f\"Stub text for {query} ({i})\",\n",
        "                metadata={\"source\": \"stub\"},\n",
        "            )\n",
        "        )\n",
        "    return hits\n",
        "\n",
        "response = SearchResponse(hits=retrieve_stub(\"example query\", top_k=3))\n",
        "print(\"hits:\", len(response.hits))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "957514f0",
      "metadata": {},
      "source": [
        "Legacy practice content from practice.ipynb\n\n",
        "### Task 3.3: Retrieval metrics\n",
        "\n",
        "Compute simple metrics (count, min/max score) for quick debugging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b46cc1a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Legacy practice content\n",
        "def retrieval_metrics(hits: list[SearchHit]) -> dict:\n",
        "    if not hits:\n",
        "        return {\"count\": 0, \"min_score\": None, \"max_score\": None}\n",
        "    scores = [h.score for h in hits]\n",
        "    return {\n",
        "        \"count\": len(hits),\n",
        "        \"min_score\": min(scores),\n",
        "        \"max_score\": max(scores),\n",
        "    }\n",
        "\n",
        "print(\"metrics:\", retrieval_metrics(response.hits))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f592845",
      "metadata": {},
      "source": [
        "Legacy practice content from practice.ipynb\n\n",
        "## Self-check\n",
        "\n",
        "- Are response models explicit and minimal?\n",
        "- Does retrieval return deterministic results?\n",
        "- Do metrics make failures visible?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}