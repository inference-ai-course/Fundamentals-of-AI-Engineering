{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Level 2 - Week 2 - 01 Vector DB Fundamentals\n",
        "\n",
        "**Estimated time:** 60-90 minutes\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- Define minimal metadata schema\n",
        "- Keep chunk_id and doc_id traceable\n",
        "- Prepare data for upsert\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n",
        "\n",
        "A vector DB is not “magic memory”. It is a storage + query system for:\n",
        "\n",
        "- vectors (embeddings)\n",
        "- stable identifiers (`chunk_id`)\n",
        "- metadata (traceability + filters)\n",
        "\n",
        "The single most important Week 2 outcome is **debuggable retrieval**.\n",
        "\n",
        "## Intuition\n",
        "\n",
        "If you can’t answer “why did this chunk come back?”, you can’t improve the system.\n",
        "\n",
        "So every chunk should be traceable:\n",
        "\n",
        "- `chunk_id` → source document (`doc_id`)\n",
        "- `chunk_id` → location (file path / url / section / page)\n",
        "- `chunk_id` → exact chunk text used later for grounding and citations\n",
        "\n",
        "## Practice Steps\n",
        "\n",
        "- Define a minimal `Chunk` data model.\n",
        "- Define the minimum metadata needed to locate the original source.\n",
        "- Choose a stable `chunk_id` scheme so re-ingestion overwrites instead of duplicating."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sample code\n",
        "\n",
        "Minimal chunk model and metadata example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Dict\n",
        "\n",
        "@dataclass\n",
        "class Chunk:\n",
        "    doc_id: str\n",
        "    chunk_id: str\n",
        "    text: str\n",
        "    metadata: Dict\n",
        "\n",
        "metadata = {\n",
        "    'doc_id': 'fastapi_docs',\n",
        "    'chunk_id': 'fastapi#001',\n",
        "    'source': 'docs',\n",
        "    'url': 'https://fastapi.tiangolo.com/',\n",
        "}\n",
        "print(metadata)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Student fill-in\n",
        "\n",
        "Add any extra metadata fields you want to track.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MIN_METADATA = {\n",
        "    'doc_id': '',\n",
        "    'chunk_id': '',\n",
        "    'source': '',\n",
        "    'text': '',\n",
        "}\n",
        "\n",
        "# TODO: add url or section fields if useful\n",
        "print(MIN_METADATA)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Self-check\n",
        "\n",
        "- Can you trace a chunk_id back to its source?\n",
        "- Is metadata small but sufficient?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Underlying theory: embeddings + similarity search\n",
        "\n",
        "### Embeddings (definition)\n",
        "\n",
        "An embedding model is a function:\n",
        "\n",
        "$$\n",
        "f: \\text{Text} \\rightarrow \\mathbb{R}^d\n",
        "$$\n",
        "\n",
        "It maps text into a $d$-dimensional vector. Individual coordinates are not “human interpretable”; the vector is meaningful as a whole.\n",
        "\n",
        "### Similarity search (what retrieval does)\n",
        "\n",
        "At ingest time you store chunk embeddings $\\mathbf{x}_i = f(\\text{chunk}_i)$.\n",
        "\n",
        "At query time you compute $\\mathbf{q} = f(\\text{query})$ and retrieve the nearest vectors to $\\mathbf{q}$ under some metric.\n",
        "\n",
        "Key implication:\n",
        "\n",
        "- retrieval returns what is *numerically close* under your embedding + metric, not what is *semantically correct*\n",
        "\n",
        "### Cosine similarity (formula + meaning)\n",
        "\n",
        "Given vectors $\\mathbf{x}$ and $\\mathbf{y}$:\n",
        "\n",
        "$$\n",
        "\\cos(\\theta) = \\frac{\\mathbf{x} \\cdot \\mathbf{y}}{\\|\\mathbf{x}\\|_2\\,\\|\\mathbf{y}\\|_2}\n",
        "$$\n",
        "\n",
        "- it measures alignment (angle) between vectors\n",
        "- it is insensitive to magnitude (vector length)\n",
        "- it is commonly used for embeddings where “meaning” is encoded in direction\n",
        "\n",
        "### Practical note: normalization\n",
        "\n",
        "If embeddings are L2-normalized (unit length), dot product and cosine similarity are equivalent:\n",
        "\n",
        "$$\n",
        "\\mathbf{x}\\cdot\\mathbf{y} = \\cos(\\theta) \\quad \\text{when } \\|\\mathbf{x}\\|_2=\\|\\mathbf{y}\\|_2=1\n",
        "$$\n",
        "\n",
        "Record:\n",
        "\n",
        "- embedding model name\n",
        "- whether vectors are normalized\n",
        "- which metric the vector DB uses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Practice: make retrieval debuggable (data model first)\n",
        "\n",
        "Goal: define the minimum fields you need so that every retrieved chunk can be traced back to its origin.\n",
        "\n",
        "You should be able to answer, for any returned `chunk_id`:\n",
        "\n",
        "- what document did this come from (`doc_id`)?\n",
        "- where did it come from (file path/url/section/page)?\n",
        "- what exact text will be used for grounding/citations (`text`)?\n",
        "\n",
        "In practice you’ll store:\n",
        "\n",
        "- stable ids (`chunk_id`)\n",
        "- the raw chunk text (`text`)\n",
        "- metadata for traceability and filtering (`doc_id`, `source`, optional `url`/`section`)\n",
        "\n",
        "Next: implement a simple chunker that outputs `Chunk` objects with stable ids + metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 1: Chunking (baseline)\n",
        "#\n",
        "# Implement chunk_text that splits a single string into fixed-size chunks.\n",
        "#\n",
        "# Requirements:\n",
        "# - deterministic: same input => same chunks\n",
        "# - traceable metadata: include doc_id and chunk_index\n",
        "# - stable chunk_id scheme: use doc_id + chunk_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0169299b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "\n",
        "def chunk_text(text: str, doc_id: str, chunk_size: int = 200) -> List[Chunk]:\n",
        "    if chunk_size <= 0:\n",
        "        raise ValueError(\"chunk_size must be > 0\")\n",
        "\n",
        "    chunks: List[Chunk] = []\n",
        "    chunk_index = 0\n",
        "    for start in range(0, len(text), chunk_size):\n",
        "        chunk_str = text[start : start + chunk_size]\n",
        "        chunk_id = f\"{doc_id}#{chunk_index:05d}\"\n",
        "        chunks.append(\n",
        "            Chunk(\n",
        "                doc_id=doc_id,\n",
        "                chunk_id=chunk_id,\n",
        "                text=chunk_str,\n",
        "                metadata={\"doc_id\": doc_id, \"chunk_index\": chunk_index},\n",
        "            )\n",
        "        )\n",
        "        chunk_index += 1\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "sample_chunks = chunk_text(\"Example document text.\" * 10, doc_id=\"doc-1\", chunk_size=120)\n",
        "print(\"chunks:\", len(sample_chunks))\n",
        "print(\"first chunk_id:\", sample_chunks[0].chunk_id)\n",
        "print(\"first metadata:\", sample_chunks[0].metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1756745",
      "metadata": {},
      "source": [
        "### Exercise 2: Embed and upsert (stubs)\n",
        "\n",
        "For now, treat embedding and upsert as *pure functions* with clear interfaces.\n",
        "\n",
        "In a real system:\n",
        "\n",
        "- `embed_texts` calls an embedding model and returns vectors (lists of floats)\n",
        "- `upsert_chunks` writes (ids, vectors, documents, metadata) into your vector DB\n",
        "\n",
        "Debuggability requirements:\n",
        "\n",
        "- assert the number of vectors matches the number of chunks\n",
        "- keep stable ids so repeated ingestion overwrites instead of duplicating\n",
        "- keep enough metadata to trace each chunk back to its source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f942f101",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Iterable, List\n",
        "\n",
        "Vector = List[float]\n",
        "\n",
        "\n",
        "def embed_texts(texts: Iterable[str]) -> List[Vector]:\n",
        "    return [[0.0] * 5 for _ in texts]\n",
        "\n",
        "\n",
        "def upsert_chunks(chunks: List[Chunk], vectors: List[Vector]) -> int:\n",
        "    assert len(chunks) == len(vectors)\n",
        "    return len(chunks)\n",
        "\n",
        "\n",
        "vectors = embed_texts([c.text for c in sample_chunks])\n",
        "count = upsert_chunks(sample_chunks, vectors)\n",
        "print(\"upserted:\", count)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
