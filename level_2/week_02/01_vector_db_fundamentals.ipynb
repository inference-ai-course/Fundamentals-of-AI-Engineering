{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Level 2 - Week 2 - 01 Vector DB Fundamentals\n",
        "\n",
        "**Estimated time:** 60-90 minutes\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- Define minimal metadata schema\n",
        "- Keep chunk_id and doc_id traceable\n",
        "- Prepare data for upsert\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n",
        "\n",
        "Vector DBs store vectors plus IDs and metadata.\n",
        "Your job is to keep retrieval debuggable.\n",
        "\n",
        "## Practice Steps\n",
        "\n",
        "- Define a Chunk model with metadata.\n",
        "- Create a sample metadata payload.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sample code\n",
        "\n",
        "Minimal chunk model and metadata example.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Dict\n",
        "\n",
        "@dataclass\n",
        "class Chunk:\n",
        "    doc_id: str\n",
        "    chunk_id: str\n",
        "    text: str\n",
        "    metadata: Dict\n",
        "\n",
        "metadata = {\n",
        "    'doc_id': 'fastapi_docs',\n",
        "    'chunk_id': 'fastapi#001',\n",
        "    'source': 'docs',\n",
        "    'url': 'https://fastapi.tiangolo.com/',\n",
        "}\n",
        "print(metadata)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Student fill-in\n",
        "\n",
        "Add any extra metadata fields you want to track.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "MIN_METADATA = {\n",
        "    'doc_id': '',\n",
        "    'chunk_id': '',\n",
        "    'source': '',\n",
        "    'text': '',\n",
        "}\n",
        "\n",
        "# TODO: add url or section fields if useful\n",
        "print(MIN_METADATA)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Self-check\n",
        "\n",
        "- Can you trace a chunk_id back to its source?\n",
        "- Is metadata small but sufficient?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Legacy practice content from practice.ipynb\n\n",
        "# Level 2 \u2014 Week 2 Practice: Vector DB Fundamentals\n",
        "\n",
        "**Estimated time:** 60\u201390 minutes\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- Describe the ingestion pipeline (parse \u2192 chunk \u2192 embed \u2192 upsert)\n",
        "- Implement a basic chunking function with metadata\n",
        "- Prepare data structures for vector DB ingestion\n",
        "- Define a minimal retrieval query shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Legacy practice content from practice.ipynb\n\n",
        "## Overview\n",
        "\n",
        "This week focuses on the ingestion side of RAG systems. We will build a small,\n",
        "checkable pipeline shape and define the data structures you will reuse later.\n",
        "\n",
        "You will:\n",
        "\n",
        "1. Define a chunk data model with metadata.\n",
        "2. Implement a simple chunking function (start naive, improve later).\n",
        "3. Sketch the embedding and upsert steps.\n",
        "\n",
        "## Practice Steps\n",
        "\n",
        "- Start with a single document string.\n",
        "- Split into chunks with IDs and metadata.\n",
        "- Stub the embed and upsert calls.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Legacy practice content\n",
        "### Task 2.1: Chunking data model\n",
        "\n",
        "Define the `Chunk` structure and implement `chunk_text`.\n",
        "Start with naive chunking (e.g., fixed size or paragraph split).\n",
        "\n",
        "Tip: keep metadata small and consistent (doc_id, chunk_index, source).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0169299b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Legacy practice content\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict\n",
        "\n",
        "@dataclass\n",
        "class Chunk:\n",
        "    doc_id: str\n",
        "    chunk_id: str\n",
        "    text: str\n",
        "    metadata: Dict\n",
        "\n",
        "def chunk_text(text: str, doc_id: str, chunk_size: int = 200) -> List[Chunk]:\n",
        "    # TODO: replace with your strategy (sentence split, overlap, etc.)\n",
        "    chunks = []\n",
        "    for idx in range(0, len(text), chunk_size):\n",
        "        chunk_text = text[idx : idx + chunk_size]\n",
        "        chunks.append(\n",
        "            Chunk(\n",
        "                doc_id=doc_id,\n",
        "                chunk_id=f\"{doc_id}-{idx // chunk_size}\",\n",
        "                text=chunk_text,\n",
        "                metadata={\"doc_id\": doc_id, \"chunk_index\": idx // chunk_size},\n",
        "            )\n",
        "        )\n",
        "    return chunks\n",
        "\n",
        "sample = chunk_text(\"Example document text.\" * 10, doc_id=\"doc-1\")\n",
        "print(\"chunks:\", len(sample))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1756745",
      "metadata": {},
      "source": [
        "Legacy practice content from practice.ipynb\n\n",
        "### Task 2.2: Embed and upsert (stubs)\n",
        "\n",
        "Create stub functions for embedding and upserting. Keep interfaces simple so you\n",
        "can swap in a real vector DB later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f942f101",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Legacy practice content\n",
        "from typing import Iterable\n",
        "\n",
        "Vector = List[float]\n",
        "\n",
        "def embed_texts(texts: Iterable[str]) -> List[Vector]:\n",
        "    # TODO: replace with real embedding model\n",
        "    return [[0.0] * 5 for _ in texts]\n",
        "\n",
        "def upsert_chunks(chunks: List[Chunk], vectors: List[Vector]) -> int:\n",
        "    # TODO: replace with vector DB client\n",
        "    assert len(chunks) == len(vectors)\n",
        "    return len(chunks)\n",
        "\n",
        "vectors = embed_texts([c.text for c in sample])\n",
        "count = upsert_chunks(sample, vectors)\n",
        "print(\"upserted:\", count)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}